{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Notebook initialized execution at 02.05.2020_14.46.18.\n"
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import pytz\n",
    "import operator\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import xgboost as xgb\n",
    "from time import sleep\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import callbacks\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.models import Model, load_model\n",
    "from tensorflow.python.keras.losses import mean_absolute_error\n",
    "from tensorflow.python.keras.layers import Dense, Input, Activation\n",
    "from tensorflow.python.keras.layers import BatchNormalization, Add, Dropout\n",
    "from tensorflow.python.keras.layers.advanced_activations import LeakyReLU\n",
    "from tensorflow.python.keras.optimizers import Adam, Adadelta, SGD\n",
    "\"\"\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings(action = 'ignore', category = FutureWarning)\n",
    "warnings.filterwarnings(action = 'ignore', category = DeprecationWarning)\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "time = datetime.now(pytz.timezone('Europe/Oslo')).strftime('%m.%d.%Y_%H.%M.%S')\n",
    "print(f'Notebook initialized execution at {time}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def memory_optimization(dfs):\n",
    "    for df in dfs:\n",
    "        del df\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_encode(df_train, df_test):\n",
    "\n",
    "    cols_with_missing_train = [col for col in df_train.columns \n",
    "                                    if df_train[col].isnull().any()]\n",
    "    cols_with_missing_test = [col for col in df_test.columns \n",
    "                                    if df_test[col].isnull().any()]\n",
    "\n",
    "    list_of_missing_cols = list(set(cols_with_missing_train) | set(cols_with_missing_test)) \n",
    "\n",
    "    df_train = df_train.drop(list_of_missing_cols, axis=1)\n",
    "    df_test = df_test.drop(list_of_missing_cols, axis=1)\n",
    "\n",
    "    s = (df_train.dtypes == 'object')\n",
    "    object_cols_train = list(s[s].index)\n",
    "    s = (df_test.dtypes == 'object')\n",
    "    object_cols_test = list(s[s].index)\n",
    "\n",
    "    object_list = list(set(object_cols_train) | set(object_cols_test)) \n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    for col in object_list:\n",
    "        df_train[col] = label_encoder.fit_transform(df_train[col])\n",
    "        df_test[col] = label_encoder.fit_transform(df_test[col])\n",
    "\n",
    "    return df_train, df_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(df_train):\n",
    "    train_X, validation_X = train_test_split(df_train, test_size = 0.1, random_state = 0)\n",
    "\n",
    "    train_X = train_X.reset_index()\n",
    "    validation_X = validation_X.reset_index()\n",
    "\n",
    "    train_y = train_X['SalePrice']\n",
    "    train_y = train_y.replace([np.inf, -np.inf], np.nan)\n",
    "    train_y = train_y.reset_index()\n",
    "    train_y = train_y.drop(['index'], axis = 1)\n",
    "    validation_y = validation_X['SalePrice']\n",
    "    validation_y = validation_y.replace([np.inf, -np.inf], np.nan)\n",
    "    validation_y = validation_y.reset_index()\n",
    "    validation_y = validation_y.drop(['index'], axis = 1)\n",
    "\n",
    "    train_X = train_X.drop('SalePrice', axis = 1)\n",
    "    validation_X = validation_X.drop('SalePrice', axis = 1)\n",
    "    \n",
    "    train_X = train_X.drop(['index'], axis = 1)\n",
    "    validation_X = validation_X.drop(['index'], axis = 1)\n",
    "    \n",
    "    return train_X, train_y, validation_X, validation_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_train( train_X, train_y, validation_X, validation_y):\n",
    "    model_name_wrt = f'../models/model.hdf5'\n",
    "\n",
    "    xgb_model = xgb.XGBRegressor(base_score = 0.5, booster = 'gbtree', colsample_bylevel = 1,\n",
    "                                 colsample_bytree = 1, gamma = 0, importance_type = 'gain',\n",
    "                                 learning_rate = 0.1, max_delta_step = 0, max_depth = 9,\n",
    "                                 min_child_weight = 1, missing = None, n_estimators = 10000, n_jobs = -1,\n",
    "                                 nthread = None, objective = 'reg:squarederror', random_state = 101, reg_alpha = 2,\n",
    "                                 reg_lambda = 0.2, scale_pos_weight = 1, seed = None, silent = False, subsample = 1)\n",
    "\n",
    "    xgb_model.fit(train_X, train_y, eval_set = [(validation_X, validation_y)], eval_metric = 'mae', \n",
    "                  early_stopping_rounds = 32, verbose = True)   \n",
    "    \n",
    "    xgb_model.save_model(model_name_wrt)\n",
    "    \n",
    "    return xgb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importance(xgb_model, train_X):\n",
    "    input_features = train_X.columns.values\n",
    "    feat_imp = xgb_model.feature_importances_\n",
    "    np.split(feat_imp, len(input_features))\n",
    "    \n",
    "    feat_imp_dict = {}\n",
    "    for i in range(0, len(input_features)):\n",
    "        feat_imp_dict[feat_imp[i]] = input_features[i]\n",
    "\n",
    "    sorted_feats = sorted(feat_imp_dict.items(), key = operator.itemgetter(0))\n",
    "    for i in range(len(sorted_feats) - 1, 0, -1):\n",
    "        print(sorted_feats[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "df_train = pd.read_csv(f'../input/train.csv')\n",
    "df_test  = pd.read_csv(f'../input/test.csv')\n",
    "\n",
    "train_X, test_X = clean_and_encode(df_train, df_test)\n",
    "\n",
    "train_X, train_y, validation_X, validation_y = split(train_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[0]\tvalidation_0-mae:162195\nWill train until validation_0-mae hasn't improved in 32 rounds.\n[1]\tvalidation_0-mae:146314\n[2]\tvalidation_0-mae:131912\n[3]\tvalidation_0-mae:119048\n[4]\tvalidation_0-mae:107330\n[5]\tvalidation_0-mae:96978.7\n[6]\tvalidation_0-mae:87810.2\n[7]\tvalidation_0-mae:79563\n[8]\tvalidation_0-mae:72097.9\n[9]\tvalidation_0-mae:65078.4\n[10]\tvalidation_0-mae:58966\n[11]\tvalidation_0-mae:53678\n[12]\tvalidation_0-mae:48882.4\n[13]\tvalidation_0-mae:44535.5\n[14]\tvalidation_0-mae:40856.5\n[15]\tvalidation_0-mae:37699.7\n[16]\tvalidation_0-mae:34819.1\n[17]\tvalidation_0-mae:32369.8\n[18]\tvalidation_0-mae:30140.5\n[19]\tvalidation_0-mae:28294.3\n[20]\tvalidation_0-mae:26664.8\n[21]\tvalidation_0-mae:25251.4\n[22]\tvalidation_0-mae:23923.2\n[23]\tvalidation_0-mae:22865.1\n[24]\tvalidation_0-mae:21902.3\n[25]\tvalidation_0-mae:21025.6\n[26]\tvalidation_0-mae:20394.2\n[27]\tvalidation_0-mae:19784.7\n[28]\tvalidation_0-mae:19167.4\n[29]\tvalidation_0-mae:18691.7\n[30]\tvalidation_0-mae:18262.3\n[31]\tvalidation_0-mae:17888.7\n[32]\tvalidation_0-mae:17551.3\n[33]\tvalidation_0-mae:17248.5\n[34]\tvalidation_0-mae:17012\n[35]\tvalidation_0-mae:16825.3\n[36]\tvalidation_0-mae:16712.9\n[37]\tvalidation_0-mae:16614.3\n[38]\tvalidation_0-mae:16501.3\n[39]\tvalidation_0-mae:16433.2\n[40]\tvalidation_0-mae:16355.2\n[41]\tvalidation_0-mae:16304.5\n[42]\tvalidation_0-mae:16250.9\n[43]\tvalidation_0-mae:16220.9\n[44]\tvalidation_0-mae:16173.7\n[45]\tvalidation_0-mae:16138.4\n[46]\tvalidation_0-mae:16109.7\n[47]\tvalidation_0-mae:16045.3\n[48]\tvalidation_0-mae:16022.2\n[49]\tvalidation_0-mae:16026.5\n[50]\tvalidation_0-mae:16014.2\n[51]\tvalidation_0-mae:16011.2\n[52]\tvalidation_0-mae:15990.2\n[53]\tvalidation_0-mae:15979.5\n[54]\tvalidation_0-mae:15974.3\n[55]\tvalidation_0-mae:15967.6\n[56]\tvalidation_0-mae:15954.6\n[57]\tvalidation_0-mae:15964.2\n[58]\tvalidation_0-mae:15963.3\n[59]\tvalidation_0-mae:15977.9\n[60]\tvalidation_0-mae:15964.6\n[61]\tvalidation_0-mae:15962.8\n[62]\tvalidation_0-mae:15966.9\n[63]\tvalidation_0-mae:15961.2\n[64]\tvalidation_0-mae:15969.5\n[65]\tvalidation_0-mae:15968\n[66]\tvalidation_0-mae:15970\n[67]\tvalidation_0-mae:15971.1\n[68]\tvalidation_0-mae:15969.5\n[69]\tvalidation_0-mae:15962\n[70]\tvalidation_0-mae:15961.4\n[71]\tvalidation_0-mae:15947.5\n[72]\tvalidation_0-mae:15940.4\n[73]\tvalidation_0-mae:15937.2\n[74]\tvalidation_0-mae:15934.8\n[75]\tvalidation_0-mae:15930.6\n[76]\tvalidation_0-mae:15926.3\n[77]\tvalidation_0-mae:15925.4\n[78]\tvalidation_0-mae:15920.9\n[79]\tvalidation_0-mae:15923.9\n[80]\tvalidation_0-mae:15906.4\n[81]\tvalidation_0-mae:15895.1\n[82]\tvalidation_0-mae:15897.3\n[83]\tvalidation_0-mae:15899.6\n[84]\tvalidation_0-mae:15898.8\n[85]\tvalidation_0-mae:15891.8\n[86]\tvalidation_0-mae:15889.8\n[87]\tvalidation_0-mae:15888.4\n[88]\tvalidation_0-mae:15893.5\n[89]\tvalidation_0-mae:15895.8\n[90]\tvalidation_0-mae:15895.1\n[91]\tvalidation_0-mae:15896.1\n[92]\tvalidation_0-mae:15888.7\n[93]\tvalidation_0-mae:15886.7\n[94]\tvalidation_0-mae:15882.9\n[95]\tvalidation_0-mae:15884\n[96]\tvalidation_0-mae:15881.3\n[97]\tvalidation_0-mae:15880.7\n[98]\tvalidation_0-mae:15883\n[99]\tvalidation_0-mae:15882.3\n[100]\tvalidation_0-mae:15879.6\n[101]\tvalidation_0-mae:15882.9\n[102]\tvalidation_0-mae:15883.5\n[103]\tvalidation_0-mae:15887.2\n[104]\tvalidation_0-mae:15887.9\n[105]\tvalidation_0-mae:15889.9\n[106]\tvalidation_0-mae:15880.8\n[107]\tvalidation_0-mae:15880.4\n[108]\tvalidation_0-mae:15874.8\n[109]\tvalidation_0-mae:15877.4\n[110]\tvalidation_0-mae:15875.5\n[111]\tvalidation_0-mae:15878.5\n[112]\tvalidation_0-mae:15877.7\n[113]\tvalidation_0-mae:15876.2\n[114]\tvalidation_0-mae:15873.8\n[115]\tvalidation_0-mae:15869.3\n[116]\tvalidation_0-mae:15867.1\n[117]\tvalidation_0-mae:15866.1\n[118]\tvalidation_0-mae:15870.8\n[119]\tvalidation_0-mae:15868.9\n[120]\tvalidation_0-mae:15866.2\n[121]\tvalidation_0-mae:15867.6\n[122]\tvalidation_0-mae:15869.1\n[123]\tvalidation_0-mae:15869.9\n[124]\tvalidation_0-mae:15872.3\n[125]\tvalidation_0-mae:15871.7\n[126]\tvalidation_0-mae:15874.5\n[127]\tvalidation_0-mae:15872\n[128]\tvalidation_0-mae:15869.6\n[129]\tvalidation_0-mae:15866.2\n[130]\tvalidation_0-mae:15864.5\n[131]\tvalidation_0-mae:15859.9\n[132]\tvalidation_0-mae:15854.9\n[133]\tvalidation_0-mae:15853.3\n[134]\tvalidation_0-mae:15852.4\n[135]\tvalidation_0-mae:15851.5\n[136]\tvalidation_0-mae:15852.2\n[137]\tvalidation_0-mae:15850.5\n[138]\tvalidation_0-mae:15853.5\n[139]\tvalidation_0-mae:15851\n[140]\tvalidation_0-mae:15853.4\n[141]\tvalidation_0-mae:15853.2\n[142]\tvalidation_0-mae:15852.3\n[143]\tvalidation_0-mae:15850.7\n[144]\tvalidation_0-mae:15850.1\n[145]\tvalidation_0-mae:15850.4\n[146]\tvalidation_0-mae:15846.8\n[147]\tvalidation_0-mae:15846.3\n[148]\tvalidation_0-mae:15847\n[149]\tvalidation_0-mae:15848.4\n[150]\tvalidation_0-mae:15847.6\n[151]\tvalidation_0-mae:15847.4\n[152]\tvalidation_0-mae:15848.1\n[153]\tvalidation_0-mae:15846.5\n[154]\tvalidation_0-mae:15846.2\n[155]\tvalidation_0-mae:15845.4\n[156]\tvalidation_0-mae:15845.6\n[157]\tvalidation_0-mae:15845.3\n[158]\tvalidation_0-mae:15845.5\n[159]\tvalidation_0-mae:15845.9\n[160]\tvalidation_0-mae:15844.9\n[161]\tvalidation_0-mae:15844.3\n[162]\tvalidation_0-mae:15846.6\n[163]\tvalidation_0-mae:15846.8\n[164]\tvalidation_0-mae:15847.1\n[165]\tvalidation_0-mae:15845.7\n[166]\tvalidation_0-mae:15846.6\n[167]\tvalidation_0-mae:15847.5\n[168]\tvalidation_0-mae:15846.3\n[169]\tvalidation_0-mae:15845.2\n[170]\tvalidation_0-mae:15845.5\n[171]\tvalidation_0-mae:15845.7\n[172]\tvalidation_0-mae:15844.5\n[173]\tvalidation_0-mae:15844.1\n[174]\tvalidation_0-mae:15843.9\n[175]\tvalidation_0-mae:15840.4\n[176]\tvalidation_0-mae:15840.7\n[177]\tvalidation_0-mae:15841.4\n[178]\tvalidation_0-mae:15842.1\n[179]\tvalidation_0-mae:15845.1\n[180]\tvalidation_0-mae:15844.6\n[181]\tvalidation_0-mae:15844.4\n[182]\tvalidation_0-mae:15842.7\n[183]\tvalidation_0-mae:15841.7\n[184]\tvalidation_0-mae:15841.5\n[185]\tvalidation_0-mae:15843.2\n[186]\tvalidation_0-mae:15843.4\n[187]\tvalidation_0-mae:15843.8\n[188]\tvalidation_0-mae:15845.6\n[189]\tvalidation_0-mae:15846.1\n[190]\tvalidation_0-mae:15846.8\n[191]\tvalidation_0-mae:15845.8\n[192]\tvalidation_0-mae:15846.6\n[193]\tvalidation_0-mae:15846.2\n[194]\tvalidation_0-mae:15847.2\n[195]\tvalidation_0-mae:15848.2\n[196]\tvalidation_0-mae:15849\n[197]\tvalidation_0-mae:15849\n[198]\tvalidation_0-mae:15849.2\n[199]\tvalidation_0-mae:15849\n[200]\tvalidation_0-mae:15848.6\n[201]\tvalidation_0-mae:15848.8\n[202]\tvalidation_0-mae:15849.1\n[203]\tvalidation_0-mae:15848.5\n[204]\tvalidation_0-mae:15849.4\n[205]\tvalidation_0-mae:15849.9\n[206]\tvalidation_0-mae:15849.4\n[207]\tvalidation_0-mae:15849.2\nStopping. Best iteration:\n[175]\tvalidation_0-mae:15840.4\n\nPredicting\nPredicted\n"
    }
   ],
   "source": [
    "xgb_model = xgb_train(train_X, train_y, validation_X, validation_y)   \n",
    "\n",
    "print('Predicting')\n",
    "test_predict = xgb_model.predict(test_X)\n",
    "print('Predicted')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make submission csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit(predictions):\n",
    "    submit = pd.read_csv('../submissions/submission.csv')  \n",
    "    submit['SalePrice'] = predictions\n",
    "    \n",
    "    time = datetime.now(pytz.timezone('Europe/Oslo')).strftime('%m.%d.%Y_%H.%M.%S')\n",
    "    submit.to_csv(f'../submissions/submission_{time}.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Notebook EoF reached at 02.05.2020_14.46.18 and submission saved.\n"
    }
   ],
   "source": [
    "submit(test_predict)\n",
    "\n",
    "print(f'Notebook EoF reached at {time} and submission saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}