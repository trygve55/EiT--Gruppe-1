{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook initialized execution at 03.04.2020_10.54.35.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import pytz\n",
    "import operator\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import xgboost as xgb\n",
    "from time import sleep\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import math\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings(action = 'ignore', category = FutureWarning)\n",
    "warnings.filterwarnings(action = 'ignore', category = DeprecationWarning)\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "time = datetime.now(pytz.timezone('Europe/Oslo')).strftime('%m.%d.%Y_%H.%M.%S')\n",
    "print(f'Notebook initialized execution at {time}.')\n",
    "#import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def memory_optimization(dfs):\n",
    "    for df in dfs:\n",
    "        del df\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_encode(df):\n",
    "\n",
    "    df = df.fillna(value = 0)\n",
    "\n",
    "    fucked_cols = ['url', 'Kommunale avg.', 'Energimerking', 'Tomt', 'Utleiedel', 'Postadresse'] \n",
    "    fucked_cols = [col for col in fucked_cols if col in df.columns]\n",
    "    df = df.drop(fucked_cols, axis=1)\n",
    "    \n",
    "    print(df.head(1))\n",
    "    cat_col = ['Boligtype', 'Eieform']\n",
    "\n",
    "    for col in cat_col:\n",
    "        if(col in df.columns):\n",
    "            df_dummies = pd.get_dummies(df[col], prefix=col)\n",
    "            df = pd.concat([df, df_dummies], axis=1).drop([col], axis=1)\n",
    "\n",
    "    print(df.head(1))\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(df_train):\n",
    "    train_X, validation_X = train_test_split(df_train, test_size = 0.2, random_state = 0)\n",
    "    test_X, validation_X = train_test_split(validation_X, test_size = 0.5, random_state = 0)\n",
    "\n",
    "    train_X = train_X.reset_index()\n",
    "    validation_X = validation_X.reset_index()\n",
    "    test_X = test_X.reset_index()\n",
    "    target = 'Totalpris'\n",
    "\n",
    "    train_y = train_X['Totalpris']\n",
    "    #train_y = train_y.replace([np.inf, -np.inf], np.nan)\n",
    "    train_y = train_y.reset_index()\n",
    "    train_y = train_y.drop(['index'], axis = 1)\n",
    "    validation_y = validation_X[target]\n",
    "    #validation_y = validation_y.replace([np.inf, -np.inf], np.nan)\n",
    "    validation_y = validation_y.reset_index()\n",
    "    validation_y = validation_y.drop(['index'], axis = 1)\n",
    "    test_y = test_X[target]\n",
    "    #test_y = test_y.replace([np.inf, -np.inf], np.nan)\n",
    "    test_y = test_y.reset_index()\n",
    "    test_y = test_y.drop(['index'], axis = 1)\n",
    "\n",
    "    train_X = train_X.drop(target, axis = 1)\n",
    "    validation_X = validation_X.drop(target, axis = 1)\n",
    "    test_X = test_X.drop(target, axis = 1)\n",
    "    \n",
    "    train_X = train_X.drop(['index'], axis = 1)\n",
    "    validation_X = validation_X.drop(['index'], axis = 1)\n",
    "    test_X = test_X.drop(['index'], axis = 1)\n",
    "\n",
    "    \n",
    "    return train_X, train_y, validation_X, validation_y, test_X, test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Omkostninger  Totalpris  Felleskost/mnd.  Soverom  Primærrom  Bruksareal  \\\n",
      "0         80320  2970320.0             2390      1.0       47.0        51.0   \n",
      "\n",
      "   Etasje  Byggeår  parkering  fiber  kabel-tv  tg 0   tg 1   tg 2  vedovn  \\\n",
      "0     2.0     2017       True  False      True  True  False  False   False   \n",
      "\n",
      "   varmepumpe  fjernvarme  terasse  utsikt  kjøkkenøy   hage  garderobe  \\\n",
      "0       False        True     True   False      False  False      False   \n",
      "\n",
      "   oppusset  oppussingsobjekt   bod        lat       lon  Rom  Fellesgjeld  \\\n",
      "0      True             False  True  62.647635  8.713596  2.0            0   \n",
      "\n",
      "   Fellesformue  Energikarakter  Oppvarmingskarakter  Telefon  \\\n",
      "0             0               1                    0      0.0   \n",
      "\n",
      "   Felleskost/mnd. etter avdragsfri periode  Festeavgift  Grunnflate  \\\n",
      "0                                       0.0          0.0         0.0   \n",
      "\n",
      "   Boligtype_Andre  Boligtype_Enebolig  Boligtype_Gårdsbruk/Småbruk  \\\n",
      "0                0                   0                            0   \n",
      "\n",
      "   Boligtype_Leilighet  Boligtype_Rekkehus  Boligtype_Tomannsbolig  \\\n",
      "0                    1                   0                       0   \n",
      "\n",
      "   Eieform_Aksje  Eieform_Andel  Eieform_Eier (Selveier)  \n",
      "0              0              0                        1  \n",
      "   Omkostninger  Totalpris  Felleskost/mnd.  Soverom  Primærrom  Bruksareal  \\\n",
      "0         80320  2970320.0             2390      1.0       47.0        51.0   \n",
      "\n",
      "   Etasje  Byggeår  parkering  fiber  kabel-tv  tg 0   tg 1   tg 2  vedovn  \\\n",
      "0     2.0     2017       True  False      True  True  False  False   False   \n",
      "\n",
      "   varmepumpe  fjernvarme  terasse  utsikt  kjøkkenøy   hage  garderobe  \\\n",
      "0       False        True     True   False      False  False      False   \n",
      "\n",
      "   oppusset  oppussingsobjekt   bod        lat       lon  Rom  Fellesgjeld  \\\n",
      "0      True             False  True  62.647635  8.713596  2.0            0   \n",
      "\n",
      "   Fellesformue  Energikarakter  Oppvarmingskarakter  Telefon  \\\n",
      "0             0               1                    0      0.0   \n",
      "\n",
      "   Felleskost/mnd. etter avdragsfri periode  Festeavgift  Grunnflate  \\\n",
      "0                                       0.0          0.0         0.0   \n",
      "\n",
      "   Boligtype_Andre  Boligtype_Enebolig  Boligtype_Gårdsbruk/Småbruk  \\\n",
      "0                0                   0                            0   \n",
      "\n",
      "   Boligtype_Leilighet  Boligtype_Rekkehus  Boligtype_Tomannsbolig  \\\n",
      "0                    1                   0                       0   \n",
      "\n",
      "   Eieform_Aksje  Eieform_Andel  Eieform_Eier (Selveier)  \n",
      "0              0              0                        1  \n",
      "      Totalpris\n",
      "0     4313820.0\n",
      "1     1991006.0\n",
      "2     3418305.0\n",
      "3     2946525.0\n",
      "4     3205436.0\n",
      "5     5894972.0\n",
      "6     2967665.0\n",
      "7    12310070.0\n",
      "8     2874628.0\n",
      "9     4572320.0\n",
      "10    3065920.0\n",
      "11    2544343.0\n",
      "12    2824017.0\n",
      "13    2941801.0\n",
      "14    3283680.0\n",
      "15    4490492.0\n",
      "16    3742420.0\n",
      "17    2421087.0\n",
      "18    1886766.0\n",
      "19    2986560.0\n",
      "20    1806817.0\n",
      "21    2256848.0\n",
      "22    2059231.0\n",
      "23    2718533.0\n",
      "24    3640092.0\n",
      "25    4818550.0\n",
      "26    2314320.0\n",
      "27    2024437.0\n",
      "28    2495455.0\n",
      "29    4500920.0\n",
      "30    3475920.0\n",
      "31    3680920.0\n",
      "32    6653472.0\n",
      "33    3278222.0\n",
      "34    2919063.0\n",
      "35    2970320.0\n",
      "36    6655820.0\n",
      "37    2245920.0\n",
      "38    7889362.0\n",
      "39    3680972.0\n",
      "40    3355742.0\n",
      "41    5391320.0\n",
      "42    8367570.0\n",
      "43    2972349.0\n",
      "44    3512070.0\n",
      "45    2799000.0\n",
      "46    5116092.0\n",
      "47    4369719.0\n",
      "48    5345670.0\n",
      "49    3065920.0\n",
      "50    5071222.0\n",
      "51    6990001.0\n",
      "52    7165972.0\n",
      "53    3289553.0\n",
      "54    4097820.0\n",
      "55    1577845.0\n",
      "56    7893842.0\n",
      "57    3145676.0\n",
      "58    3503920.0\n",
      "59    5146692.0\n",
      "60    3997420.0\n",
      "61    3582784.0\n",
      "62    2490531.0\n",
      "63    3885920.0\n",
      "64    4119307.0\n",
      "65    3547670.0\n",
      "66    3748222.0\n",
      "67    4099872.0\n",
      "68    3339200.0\n",
      "69    4920820.0\n",
      "70    4098099.0\n",
      "71    7165920.0\n",
      "72    5540170.0\n",
      "73    2699686.0\n",
      "74    3588320.0\n",
      "75    3082048.0\n",
      "76   10985000.0\n",
      "77    5423420.0\n",
      "78    6653420.0\n",
      "79    3735203.0\n",
      "80    5950632.0\n",
      "81   10758370.0\n",
      "82    2741437.0\n",
      "83    3384884.0\n",
      "84    3578592.0\n",
      "85    3387492.0\n",
      "86    4417461.0\n",
      "87    3270920.0\n",
      "88    3323254.0\n",
      "89    2213413.0\n",
      "90    3783420.0\n",
      "91    2322378.0\n",
      "92    2129903.0\n",
      "93    3342320.0\n",
      "94    4500920.0\n",
      "95    4101320.0\n",
      "96    2323681.0\n",
      "97    4610692.0\n",
      "98    3592492.0\n",
      "99    2032383.0\n",
      "100   7791320.0\n",
      "101   2657578.0\n",
      "102  10771070.0\n",
      "103   3061157.0\n",
      "104  11277192.0\n",
      "105   4135860.0\n",
      "106   4873920.0\n",
      "107   3270920.0\n",
      "108   4808420.0\n",
      "109   2788959.0\n",
      "110   9538034.0\n",
      "111   5730972.0\n",
      "112   6109820.0\n",
      "113   2860920.0\n",
      "114   3397719.0\n",
      "115   1932687.0\n",
      "116   3073330.0\n",
      "117   5123320.0\n",
      "118   2438780.0\n",
      "119   4592297.0\n",
      "120   4080842.0\n",
      "121   3215572.0\n",
      "122   5647072.0\n",
      "123   4434920.0\n",
      "124   3790320.0\n",
      "125   3065920.0\n",
      "126   2747050.0\n",
      "127   2566788.0\n",
      "128   3020165.0\n",
      "129   4511222.0\n",
      "130   4097820.0\n",
      "131   8918722.0\n",
      "132   4613520.0\n",
      "133   5125700.0\n",
      "134   3483178.0\n",
      "135   3790572.0\n",
      "136   4562499.0\n",
      "137   3289377.0\n",
      "138   3058475.0\n",
      "139   4767420.0\n",
      "140   3150917.0\n",
      "141   5135842.0\n",
      "142   2895060.0\n",
      "143   2758420.0\n",
      "144   9990578.0\n",
      "145   3537420.0\n",
      "146   2691808.0\n",
      "147   4664920.0\n",
      "148   4398592.0\n",
      "149   2435460.0\n",
      "150   3393450.0\n",
      "151   8159592.0\n",
      "152   3964320.0\n",
      "153   2952062.0\n",
      "154   2016938.0\n",
      "155   6048792.0\n",
      "156   3947420.0\n",
      "157   4362420.0\n",
      "158   2153670.0\n",
      "159   4296635.0\n",
      "160   1251681.0\n",
      "161   3813413.0\n",
      "162   5979320.0\n",
      "163   2712517.0\n",
      "164   3626723.0\n",
      "165   4871122.0\n",
      "166   2451092.0\n",
      "167   2998060.0\n",
      "168   3272323.0\n",
      "169   2353283.0\n",
      "170  11184822.0\n",
      "171   5941670.0\n",
      "172   2553420.0\n",
      "173   5382420.0\n",
      "174   1474417.0\n",
      "175   2658183.0\n",
      "176   3522990.0\n",
      "177   3031820.0\n",
      "178   2451092.0\n",
      "179   4309243.0\n",
      "180   6158508.0\n",
      "181   9236070.0\n",
      "182   2555920.0\n",
      "183   3589300.0\n",
      "184   2787889.0\n",
      "185   4090920.0\n",
      "186   5027712.0\n",
      "187   4104992.0\n",
      "188   2750648.0\n",
      "189   4364320.0\n",
      "190   3225747.0\n",
      "191   4808420.0\n",
      "192   5638820.0\n",
      "193   6524420.0\n",
      "194   3568544.0\n",
      "195   2844422.0\n",
      "196   7180392.0\n",
      "197   3379222.0\n",
      "198   3680920.0\n",
      "199   1919423.0\n",
      "200  16925342.0\n",
      "201   2942460.0\n",
      "202   3548840.0\n",
      "203   3903070.0\n",
      "204   3544998.0\n",
      "205   4330818.0\n",
      "206   2830790.0\n",
      "207   2615910.0\n",
      "208   4870172.0\n",
      "209   5020320.0\n",
      "210   3335389.0\n",
      "211   3610850.0\n",
      "212   8713722.0\n",
      "213   4034948.0\n",
      "214   3257320.0\n",
      "215   2451872.0\n",
      "216   2656092.0\n",
      "217   6140920.0\n",
      "218   6346092.0\n",
      "219   3475920.0\n",
      "220   3603572.0\n",
      "221   2051050.0\n",
      "222   3052320.0\n",
      "223   3578420.0\n",
      "224   4422745.0\n",
      "225   2864914.0\n",
      "226   5646070.0\n",
      "227   5691092.0\n",
      "228   1990206.0\n",
      "229   2598982.0\n",
      "230  14256070.0\n",
      "231   2960101.0\n",
      "232   2815160.0\n",
      "233   2105395.0\n",
      "234   3064750.0\n",
      "235   2352732.0\n",
      "236   3274722.0\n",
      "237   3339492.0\n",
      "238   4987296.0\n",
      "239   2999142.0\n",
      "240   2860920.0\n",
      "241  10148670.0\n",
      "242  11216962.0\n",
      "243   1938592.0\n",
      "244   3269750.0\n",
      "245   8662210.0\n",
      "246   2360554.0\n",
      "247   2694645.0\n",
      "248   3783420.0\n",
      "249   3152248.0\n",
      "250   2253742.0\n",
      "251   5590000.0\n",
      "252   2781051.0\n",
      "253   4777320.0\n",
      "254   6312320.0\n",
      "255   4210900.0\n",
      "256   3270920.0\n",
      "257   3988416.0\n",
      "258   4500800.0\n",
      "259   3338170.0\n",
      "260   4630385.0\n",
      "261   2656092.0\n",
      "262   2210670.0\n",
      "263   5536170.0\n",
      "264  12198722.0\n",
      "265   2913566.0\n",
      "266   2663779.0\n",
      "267   5433040.0\n",
      "268   3307420.0\n",
      "269  17450222.0\n",
      "270   3072080.0\n",
      "271   2972113.0\n",
      "272   4963042.0\n",
      "273   3251838.0\n",
      "274   3775826.0\n",
      "275   2277716.0\n",
      "276   4921020.0\n",
      "277   3482687.0\n",
      "278   2479000.0\n",
      "279   3911854.0\n",
      "280   3729291.0\n",
      "281   3796950.0\n",
      "282   3106800.0\n",
      "283   2897959.0\n",
      "284   2410092.0\n",
      "285   3258159.0\n",
      "286   3020989.0\n",
      "287   6925570.0\n",
      "288   4305872.0\n",
      "289   2477966.0\n",
      "290   4100992.0\n",
      "291   6007320.0\n",
      "292   6663670.0\n",
      "293   3783300.0\n",
      "294   5013420.0\n",
      "295   3024920.0\n",
      "296  14607592.0\n",
      "297   3326190.0\n",
      "298   2129730.0\n",
      "299   2031375.0\n",
      "300   3988592.0\n",
      "301   3282420.0\n",
      "302  10605542.0\n",
      "303   2463822.0\n",
      "304   1858574.0\n",
      "305   3544492.0\n",
      "306   4818722.0\n",
      "307   1880065.0\n",
      "308   2860920.0\n",
      "309   3898616.0\n",
      "310   2625320.0\n",
      "311   3186322.0\n",
      "312   4507820.0\n",
      "313   3069213.0\n",
      "314   4193420.0\n",
      "315   5042259.0\n",
      "316   4213742.0\n",
      "317   5894920.0\n",
      "318   4402784.0\n",
      "319   4259232.0\n",
      "320   5328492.0\n",
      "321   2971999.0\n",
      "322   9226170.0\n",
      "323   3265640.0\n",
      "324   1794258.0\n",
      "325   5437400.0\n",
      "326   2256170.0\n",
      "327   3397358.0\n",
      "328   3373420.0\n",
      "329   5323099.0\n",
      "330   6146670.0\n",
      "331   3278245.0\n",
      "332   2355320.0\n",
      "333   1845560.0\n",
      "334   3846042.0\n",
      "335   5122820.0\n",
      "336   2568640.0\n",
      "337   2947000.0\n",
      "338   2731417.0\n",
      "339   4718822.0\n",
      "340   2553592.0\n",
      "341   6132950.0\n",
      "342   3388060.0\n",
      "343   3988592.0\n",
      "344   2521687.0\n",
      "345   2963427.0\n",
      "346   4869920.0\n",
      "347   2399793.0\n",
      "348   3282132.0\n",
      "349   3578420.0\n",
      "350   2795922.0\n",
      "351   2110344.0\n",
      "352   3422908.0\n",
      "353   8717892.0\n",
      "354   6045820.0\n",
      "355   1761846.0\n",
      "356   2977145.0\n",
      "357   4705920.0\n",
      "358   2607212.0\n",
      "359   7473472.0\n",
      "360   4839572.0\n",
      "361   3687820.0\n",
      "362   3463587.0\n",
      "363   4390960.0\n",
      "364   2597472.0\n",
      "365   4254920.0\n",
      "366   2201664.0\n",
      "367   4388321.0\n",
      "368   2920322.0\n",
      "369   4386770.0\n",
      "370   4808420.0\n",
      "371   3072820.0\n",
      "372   2386538.0\n",
      "373   2963420.0\n",
      "374   4511374.0\n",
      "375   9697320.0\n",
      "376   3206450.0\n",
      "377   3346712.0\n",
      "378   4610320.0\n",
      "379   3790320.0\n",
      "380   4310661.0\n",
      "381   2348420.0\n",
      "382   3936341.0\n",
      "383   3688742.0\n",
      "384   4193472.0\n",
      "385   6048962.0\n",
      "386   4089750.0\n",
      "387   4101170.0\n",
      "388   3790482.0\n",
      "389   5115972.0\n",
      "390   2911920.0\n",
      "391   2469395.0\n",
      "392   4495000.0\n",
      "393   2675220.0\n",
      "394   3187415.0\n",
      "395   3844920.0\n",
      "396   2621820.0\n",
      "397   4613320.0\n",
      "398   4398472.0\n",
      "399   1690219.0\n",
      "400   4127724.0\n",
      "401   2797610.0\n",
      "402   2563291.0\n",
      "403   5444934.0\n",
      "404   4122745.0\n",
      "405  14863722.0\n",
      "406   3588722.0\n",
      "407   3168420.0\n",
      "408   4423425.0\n",
      "409   3270920.0\n",
      "410   2587443.0\n",
      "411   3907754.0\n",
      "412   5074920.0\n",
      "413   3076222.0\n",
      "414   3324763.0\n",
      "415   5565692.0\n",
      "416   7703170.0\n",
      "417   3038551.0\n",
      "418   5239822.0\n",
      "419   3239051.0\n",
      "420   2866666.0\n",
      "421   6906222.0\n",
      "422   3680920.0\n",
      "423   4084982.0\n",
      "424   2659951.0\n",
      "425   3281170.0\n",
      "426   2971520.0\n",
      "427   5010519.0\n",
      "428   3321051.0\n",
      "429   5331170.0\n",
      "430   3644006.0\n",
      "431   2963292.0\n",
      "432  13326170.0\n",
      "433   4705920.0\n",
      "434   9912349.0\n",
      "435   4712820.0\n",
      "436   5648570.0\n",
      "437   3037462.0\n",
      "438   3885920.0\n",
      "439   4295920.0\n",
      "440   4091092.0\n",
      "441   4073957.0\n",
      "442   3978492.0\n",
      "443   2662820.0\n",
      "444   5628592.0\n",
      "445   4979320.0\n",
      "446   2603991.0\n",
      "447   4018000.0\n",
      "448   5803040.0\n",
      "449   4295920.0\n",
      "450   2819800.0\n",
      "451   1854750.0\n",
      "452   2824185.0\n",
      "453   3886092.0\n",
      "454   4465670.0\n",
      "455   4302820.0\n",
      "456   2592195.0\n",
      "457   3175320.0\n",
      "458   3886092.0\n",
      "459   4918492.0\n",
      "460   7678472.0\n",
      "461   3783420.0\n",
      "462   2143420.0\n",
      "463   1913820.0\n",
      "464   4254972.0\n",
      "465   3336389.0\n",
      "466   5320920.0\n",
      "467   3214810.0\n",
      "468   3998320.0\n",
      "469   3686092.0\n",
      "470   3133937.0\n",
      "471   3275232.0\n",
      "472   2326943.0\n",
      "473   6099920.0\n",
      "474   3578592.0\n",
      "475   2593457.0\n",
      "476   3483372.0\n",
      "477   2547153.0\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "df = pd.read_csv(f'../input/trondheimv3.csv')\n",
    "\n",
    "df = clean_and_encode(df)\n",
    "\n",
    "train_x, train_y, validation_x, validation_y, test_x, test_y= split(df)\n",
    "\n",
    "print(train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Price scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scaling(data):\n",
    "    scaler = preprocessing.MinMaxScaler().fit(data)\n",
    "    return scaler.data_max_ - scaler.data_min_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_scale = get_scaling(train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_dataset(data):\n",
    "    x = data.values\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    x_scaled = min_max_scaler.fit_transform(x)\n",
    "    return pd.DataFrame(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = normalize_dataset(train_y)\n",
    "train_x = normalize_dataset(train_x)\n",
    "validation_x = normalize_dataset(validation_x)\n",
    "validation_y = normalize_dataset(validation_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(44,), name='digits')\n",
    "x = layers.Dense(44, activation='relu', name='dense_1')(inputs)\n",
    "x = layers.Dropout(0.2, input_shape=(44,))(x)\n",
    "x = layers.Dense(44, activation='relu', name='dense_2')(x)\n",
    "x = layers.Dropout(0.2, input_shape=(60,))(x)\n",
    "x = layers.Dense(44, activation='relu', name='dense_3')(x)\n",
    "outputs = layers.Dense(1, name='predictions')(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='sgd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Fit model on training data\n",
      "Train on 478 samples, validate on 60 samples\n",
      "Epoch 1/3\n",
      "478/478 [==============================] - 0s 651us/sample - loss: 0.0582 - val_loss: 0.0290\n",
      "Epoch 2/3\n",
      "478/478 [==============================] - 0s 42us/sample - loss: 0.0417 - val_loss: 0.0308\n",
      "Epoch 3/3\n",
      "478/478 [==============================] - 0s 61us/sample - loss: 0.0434 - val_loss: 0.0295\n",
      "\n",
      "history dict: {'loss': [0.058207701221420174, 0.041695633380981666, 0.043442133424421735], 'val_loss': [0.02897556498646736, 0.030796093866229057, 0.02948654443025589]}\n"
     ]
    }
   ],
   "source": [
    "print('# Fit model on training data')\n",
    "history = model.fit(train_x, train_y,\n",
    "                    batch_size=64,\n",
    "                    epochs=3,\n",
    "                    validation_data=(validation_x, validation_y))\n",
    "\n",
    "print('\\nhistory dict:', history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 51us/sample - loss: 0.0295\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(validation_x, validation_y, batch_size=64)\n",
    "print(results.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[477638.99890182]\n"
     ]
    }
   ],
   "source": [
    "print(results*train_y_scale)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
