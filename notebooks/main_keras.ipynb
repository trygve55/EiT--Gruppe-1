{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook initialized execution at 03.04.2020_10.20.01.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import pytz\n",
    "import operator\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import xgboost as xgb\n",
    "from time import sleep\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import math\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings(action = 'ignore', category = FutureWarning)\n",
    "warnings.filterwarnings(action = 'ignore', category = DeprecationWarning)\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "time = datetime.now(pytz.timezone('Europe/Oslo')).strftime('%m.%d.%Y_%H.%M.%S')\n",
    "print(f'Notebook initialized execution at {time}.')\n",
    "#import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def memory_optimization(dfs):\n",
    "    for df in dfs:\n",
    "        del df\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_encode(df):\n",
    "\n",
    "    df = df.fillna(value = 0)\n",
    "\n",
    "    fucked_cols = ['url', 'Kommunale avg.', 'Energimerking', 'Tomt', 'Utleiedel', 'Postadresse'] \n",
    "    fucked_cols = [col for col in fucked_cols if col in df.columns]\n",
    "    df = df.drop(fucked_cols, axis=1)\n",
    "    \n",
    "    print(df.head(1))\n",
    "    cat_col = ['Boligtype', 'Eieform']\n",
    "\n",
    "    for col in cat_col:\n",
    "        if(col in df.columns):\n",
    "            df_dummies = pd.get_dummies(df[col], prefix=col)\n",
    "            df = pd.concat([df, df_dummies], axis=1).drop([col], axis=1)\n",
    "\n",
    "    print(df.head(1))\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(df_train):\n",
    "    train_X, validation_X = train_test_split(df_train, test_size = 0.2, random_state = 0)\n",
    "    test_X, validation_X = train_test_split(validation_X, test_size = 0.5, random_state = 0)\n",
    "\n",
    "    train_X = train_X.reset_index()\n",
    "    validation_X = validation_X.reset_index()\n",
    "    test_X = test_X.reset_index()\n",
    "    target = 'Totalpris'\n",
    "\n",
    "    train_y = train_X['Totalpris']\n",
    "    #train_y = train_y.replace([np.inf, -np.inf], np.nan)\n",
    "    train_y = train_y.reset_index()\n",
    "    train_y = train_y.drop(['index'], axis = 1)\n",
    "    validation_y = validation_X[target]\n",
    "    #validation_y = validation_y.replace([np.inf, -np.inf], np.nan)\n",
    "    validation_y = validation_y.reset_index()\n",
    "    validation_y = validation_y.drop(['index'], axis = 1)\n",
    "    test_y = test_X[target]\n",
    "    #test_y = test_y.replace([np.inf, -np.inf], np.nan)\n",
    "    test_y = test_y.reset_index()\n",
    "    test_y = test_y.drop(['index'], axis = 1)\n",
    "\n",
    "    train_X = train_X.drop(target, axis = 1)\n",
    "    validation_X = validation_X.drop(target, axis = 1)\n",
    "    test_X = test_X.drop(target, axis = 1)\n",
    "    \n",
    "    train_X = train_X.drop(['index'], axis = 1)\n",
    "    validation_X = validation_X.drop(['index'], axis = 1)\n",
    "    test_X = test_X.drop(['index'], axis = 1)\n",
    "\n",
    "    \n",
    "    return train_X, train_y, validation_X, validation_y, test_X, test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Omkostninger  Totalpris  Felleskost/mnd.  Soverom  Primærrom  Bruksareal  \\\n",
      "0         80320  2970320.0             2390      1.0       47.0        51.0   \n",
      "\n",
      "   Etasje  Byggeår  parkering  fiber  kabel-tv  tg 0   tg 1   tg 2  vedovn  \\\n",
      "0     2.0     2017       True  False      True  True  False  False   False   \n",
      "\n",
      "   varmepumpe  fjernvarme  terasse  utsikt  kjøkkenøy   hage  garderobe  \\\n",
      "0       False        True     True   False      False  False      False   \n",
      "\n",
      "   oppusset  oppussingsobjekt   bod        lat       lon  Rom  Fellesgjeld  \\\n",
      "0      True             False  True  62.647635  8.713596  2.0            0   \n",
      "\n",
      "   Fellesformue  Energikarakter  Oppvarmingskarakter  Telefon  \\\n",
      "0             0               1                    0      0.0   \n",
      "\n",
      "   Felleskost/mnd. etter avdragsfri periode  Festeavgift  Grunnflate  \\\n",
      "0                                       0.0          0.0         0.0   \n",
      "\n",
      "   Boligtype_Andre  Boligtype_Enebolig  Boligtype_Gårdsbruk/Småbruk  \\\n",
      "0                0                   0                            0   \n",
      "\n",
      "   Boligtype_Leilighet  Boligtype_Rekkehus  Boligtype_Tomannsbolig  \\\n",
      "0                    1                   0                       0   \n",
      "\n",
      "   Eieform_Aksje  Eieform_Andel  Eieform_Eier (Selveier)  \n",
      "0              0              0                        1  \n",
      "   Omkostninger  Totalpris  Felleskost/mnd.  Soverom  Primærrom  Bruksareal  \\\n",
      "0         80320  2970320.0             2390      1.0       47.0        51.0   \n",
      "\n",
      "   Etasje  Byggeår  parkering  fiber  kabel-tv  tg 0   tg 1   tg 2  vedovn  \\\n",
      "0     2.0     2017       True  False      True  True  False  False   False   \n",
      "\n",
      "   varmepumpe  fjernvarme  terasse  utsikt  kjøkkenøy   hage  garderobe  \\\n",
      "0       False        True     True   False      False  False      False   \n",
      "\n",
      "   oppusset  oppussingsobjekt   bod        lat       lon  Rom  Fellesgjeld  \\\n",
      "0      True             False  True  62.647635  8.713596  2.0            0   \n",
      "\n",
      "   Fellesformue  Energikarakter  Oppvarmingskarakter  Telefon  \\\n",
      "0             0               1                    0      0.0   \n",
      "\n",
      "   Felleskost/mnd. etter avdragsfri periode  Festeavgift  Grunnflate  \\\n",
      "0                                       0.0          0.0         0.0   \n",
      "\n",
      "   Boligtype_Andre  Boligtype_Enebolig  Boligtype_Gårdsbruk/Småbruk  \\\n",
      "0                0                   0                            0   \n",
      "\n",
      "   Boligtype_Leilighet  Boligtype_Rekkehus  Boligtype_Tomannsbolig  \\\n",
      "0                    1                   0                       0   \n",
      "\n",
      "   Eieform_Aksje  Eieform_Andel  Eieform_Eier (Selveier)  \n",
      "0              0              0                        1  \n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "df = pd.read_csv(f'../input/trondheimv3.csv')\n",
    "\n",
    "df = clean_and_encode(df)\n",
    "\n",
    "train_x, train_y, validation_x, validation_y, test_x, test_y= split(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_dataset(data):\n",
    "    x = data.values\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    x_scaled = min_max_scaler.fit_transform(x)\n",
    "    return pd.DataFrame(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = normalize_dataset(train_y)\n",
    "train_x = normalize_dataset(train_x)\n",
    "validation_x = normalize_dataset(validation_x)\n",
    "validation_y = normalize_dataset(validation_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(44,), name='digits')\n",
    "x = layers.Dense(44, activation='relu', name='dense_1')(inputs)\n",
    "x = layers.Dense(44, activation='relu', name='dense_2')(x)\n",
    "outputs = layers.Dense(1, name='predictions')(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='sgd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Fit model on training data\n",
      "Train on 478 samples, validate on 60 samples\n",
      "Epoch 1/3\n",
      "478/478 [==============================] - 1s 1ms/sample - loss: 0.0470 - val_loss: 0.0522\n",
      "Epoch 2/3\n",
      "478/478 [==============================] - 0s 48us/sample - loss: 0.0364 - val_loss: 0.0439\n",
      "Epoch 3/3\n",
      "478/478 [==============================] - 0s 58us/sample - loss: 0.0328 - val_loss: 0.0398\n",
      "\n",
      "history dict: {'loss': [0.04702644987678677, 0.03637864001905818, 0.03275918257598099], 'val_loss': [0.05215558037161827, 0.04388635978102684, 0.039815742522478104]}\n"
     ]
    }
   ],
   "source": [
    "print('# Fit model on training data')\n",
    "history = model.fit(train_x, train_y,\n",
    "                    batch_size=64,\n",
    "                    epochs=3,\n",
    "                    validation_data=(validation_x, validation_y))\n",
    "\n",
    "print('\\nhistory dict:', history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 33us/sample - loss: 0.0398\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(validation_x, validation_y, batch_size=64)\n",
    "print(results.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
