{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook initialized execution at 04.21.2020_12.43.08.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import pytz\n",
    "import operator\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import matplotlib as mtp\n",
    "from time import sleep\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import preprocessing\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "import finn_data\n",
    "import tensorflow as tf\n",
    "from tensorflow import math\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.activations import relu, elu\n",
    "from keras.layers import Dense, Dropout\n",
    "from talos.model import early_stopper\n",
    "from talos.utils.best_model import activate_model\n",
    "from talos import Evaluate\n",
    "import talos\n",
    "from talos import Reporting\n",
    "from talos import Deploy\n",
    "from talos import Restore\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "import finn_data\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings(action = 'ignore', category = FutureWarning)\n",
    "warnings.filterwarnings(action = 'ignore', category = DeprecationWarning)\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "time = datetime.now(pytz.timezone('Europe/Oslo')).strftime('%m.%d.%Y_%H.%M.%S')\n",
    "print(f'Notebook initialized execution at {time}.')\n",
    "#import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def memory_optimization(dfs):\n",
    "    for df in dfs:\n",
    "        del df\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning removed 1.06 % of the original values\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "start_time = datetime.now()\n",
    "scaler = MinMaxScaler()\n",
    "train_x, train_y, validation_x, validation_y, test_x, test_y, scaler = datasets.load(f'../input/hele_norge.csv', scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'activation_1':['relu', 'elu'],\n",
    "     'activation_2':['relu', 'elu'],\n",
    "     'activation_3':['relu', 'elu'],\n",
    "     'optimizer': ['Adam', \"RMSprop\"],\n",
    "     'loss-functions': ['mse'],\n",
    "     'neurons_HL1': [50, 100, 200, 400],\n",
    "     'neurons_HL2': [40, 80, 160, 320],\n",
    "     'neurons_HL3': [40, 80, 160, 320, None],\n",
    "     'dropout1': [0.1, 0.2, 0.3],\n",
    "     'dropout2': [0.1, 0.2, 0.3],\n",
    "     'batch_size': [100, 250, 500],\n",
    "     'epochs': [400, 900]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def talolos(x_train, y_train, x_val, y_val, parameters):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(parameters['neurons_HL1'], \n",
    "    input_shape=(train_x.shape[1],), \n",
    "    activation=parameters['activation_1'],use_bias=True))\n",
    "\n",
    "    model.add(Dropout(parameters['dropout1']))\n",
    "\n",
    "    model.add(Dense(parameters['neurons_HL2'], \n",
    "    activation=parameters['activation_2'], use_bias=True))\n",
    "\n",
    "    model.add(Dropout(parameters['dropout1']))\n",
    "    \n",
    "    if parameters['neurons_HL3']:\n",
    "        model.add(Dense(parameters['neurons_HL3'], \n",
    "        activation=parameters['activation_3'], use_bias=True))\n",
    "\n",
    "\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "\n",
    "    model.compile(optimizer=parameters['optimizer'], loss=parameters['loss-functions'], \n",
    "    metrics=['mse', 'mae'])\n",
    "\n",
    "    history = model.fit(x_train, y_train,\n",
    "            batch_size=parameters['batch_size'],epochs=parameters['epochs'],\n",
    "            verbose=0,validation_data=[x_val, y_val],\n",
    "            callbacks=[early_stopper(epochs=parameters['epochs'], \n",
    "            mode='moderate',monitor='val_loss', patience=1)])\n",
    "    \n",
    "    return history, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [01:45<00:00, 52.73s/it]\n"
     ]
    }
   ],
   "source": [
    "t = talos.Scan(x=np.array(train_x),\n",
    "               y=np.array(train_y),\n",
    "               x_val=np.array(validation_x),\n",
    "               y_val=np.array(validation_y),\n",
    "               model=talolos,\n",
    "               params=parameters,\n",
    "               experiment_name='oloo',\n",
    "             round_limit=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_transform(scaler, value):\n",
    "    mat = np.zeros((1, scaler.scale_.shape[0]))\n",
    "    mat[0, 0] = value\n",
    "    return scaler.inverse_transform(mat)[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def evaluate(scan_model, test_x, test_y):\n",
    "    eval_model = Evaluate(scan_model)\n",
    "    results = eval_model.evaluate(np.array(test_x), np.array(test_y), task='continuous',folds=10, metric='loss')\n",
    "    return np.array([inverse_transform(scaler,result) for result in results])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 't' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-dec80e71bd83>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#t.data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 't' is not defined"
     ]
    }
   ],
   "source": [
    "#t.data\n",
    "results = evaluate(t, test_x, test_y)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve old parameters (Last inn 2000-kjoring.csv fra drive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ligger på drive:\n",
    "res = Reporting('../input/2000_kjoring.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = res.data.sort_values('val_mae', ascending=True).iloc[0]\n",
    "best = pd.DataFrame(best)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_param(df, key):\n",
    "    return df.loc[key].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'activation_1': extract_param(best,'activation_1'),\n",
    " 'activation_2': extract_param(best,'activation_2'),\n",
    " 'activation_3': extract_param(best,'activation_3'),\n",
    " 'optimizer': extract_param(best,'optimizer'),\n",
    " 'loss-functions': extract_param(best,'loss-functions'),\n",
    " 'neurons_HL1': extract_param(best,'neurons_HL1'),\n",
    " 'neurons_HL2': extract_param(best,'neurons_HL2'),\n",
    " 'neurons_HL3': extract_param(best,'neurons_HL3'),\n",
    " 'dropout1': extract_param(best,'dropout1'),\n",
    " 'dropout2': extract_param(best,'dropout2'),\n",
    " 'batch_size': extract_param(best,'batch_size'),\n",
    " 'epochs': extract_param(best,'epochs')}\n",
    "def best_model():\n",
    "    parameters = {'activation_1': extract_param(best,'activation_1'),\n",
    "     'activation_2': extract_param(best,'activation_2'),\n",
    "     'activation_3': extract_param(best,'activation_3'),\n",
    "     'optimizer': extract_param(best,'optimizer'),\n",
    "     'loss-functions': extract_param(best,'loss-functions'),\n",
    "     'neurons_HL1': extract_param(best,'neurons_HL1'),\n",
    "     'neurons_HL2': extract_param(best,'neurons_HL2'),\n",
    "     'neurons_HL3': extract_param(best,'neurons_HL3'),\n",
    "     'dropout1': extract_param(best,'dropout1'),\n",
    "     'dropout2': extract_param(best,'dropout2'),\n",
    "     'batch_size': extract_param(best,'batch_size'),\n",
    "     'epochs': extract_param(best,'epochs')\n",
    "    }\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(parameters['neurons_HL1'], \n",
    "    input_shape=(train_x.shape[1],), \n",
    "    activation=parameters['activation_1'],use_bias=True))\n",
    "\n",
    "    model.add(Dropout(parameters['dropout1']))\n",
    "\n",
    "    model.add(Dense(parameters['neurons_HL2'], \n",
    "    activation=parameters['activation_2'], use_bias=True))\n",
    "\n",
    "    model.add(Dropout(parameters['dropout1']))\n",
    "    \n",
    "    if parameters['neurons_HL3'] != 'None':\n",
    "        model.add(Dense(parameters['neurons_HL3'], \n",
    "        activation=parameters['activation_3'], use_bias=True))\n",
    "\n",
    "\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "\n",
    "    model.compile(optimizer=parameters['optimizer'], loss=parameters['loss-functions'], \n",
    "    metrics=['mse', 'mae'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train retrieved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jonas\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/300\n",
      " - 1s - loss: 0.0186 - mse: 0.0186 - mae: 0.1073\n",
      "Epoch 2/300\n",
      " - 0s - loss: 0.0103 - mse: 0.0103 - mae: 0.0780\n",
      "Epoch 3/300\n",
      " - 0s - loss: 0.0079 - mse: 0.0079 - mae: 0.0659\n",
      "Epoch 4/300\n",
      " - 0s - loss: 0.0067 - mse: 0.0067 - mae: 0.0584\n",
      "Epoch 5/300\n",
      " - 1s - loss: 0.0057 - mse: 0.0057 - mae: 0.0534\n",
      "Epoch 6/300\n",
      " - 0s - loss: 0.0054 - mse: 0.0054 - mae: 0.0511\n",
      "Epoch 7/300\n",
      " - 0s - loss: 0.0051 - mse: 0.0051 - mae: 0.0489\n",
      "Epoch 8/300\n",
      " - 0s - loss: 0.0049 - mse: 0.0049 - mae: 0.0475\n",
      "Epoch 9/300\n",
      " - 0s - loss: 0.0047 - mse: 0.0047 - mae: 0.0460\n",
      "Epoch 10/300\n",
      " - 0s - loss: 0.0045 - mse: 0.0045 - mae: 0.0453\n",
      "Epoch 11/300\n",
      " - 0s - loss: 0.0045 - mse: 0.0045 - mae: 0.0445\n",
      "Epoch 12/300\n",
      " - 1s - loss: 0.0044 - mse: 0.0044 - mae: 0.0442\n",
      "Epoch 13/300\n",
      " - 0s - loss: 0.0043 - mse: 0.0043 - mae: 0.0435\n",
      "Epoch 14/300\n",
      " - 0s - loss: 0.0042 - mse: 0.0042 - mae: 0.0431\n",
      "Epoch 15/300\n",
      " - 0s - loss: 0.0043 - mse: 0.0043 - mae: 0.0432\n",
      "Epoch 16/300\n",
      " - 0s - loss: 0.0041 - mse: 0.0041 - mae: 0.0422\n",
      "Epoch 17/300\n",
      " - 0s - loss: 0.0041 - mse: 0.0041 - mae: 0.0422\n",
      "Epoch 18/300\n",
      " - 0s - loss: 0.0040 - mse: 0.0040 - mae: 0.0417\n",
      "Epoch 19/300\n",
      " - 0s - loss: 0.0040 - mse: 0.0040 - mae: 0.0412\n",
      "Epoch 20/300\n",
      " - 0s - loss: 0.0039 - mse: 0.0039 - mae: 0.0410\n",
      "Epoch 21/300\n",
      " - 0s - loss: 0.0039 - mse: 0.0039 - mae: 0.0407\n",
      "Epoch 22/300\n",
      " - 0s - loss: 0.0038 - mse: 0.0038 - mae: 0.0404\n",
      "Epoch 23/300\n",
      " - 0s - loss: 0.0038 - mse: 0.0038 - mae: 0.0402\n",
      "Epoch 24/300\n",
      " - 0s - loss: 0.0037 - mse: 0.0037 - mae: 0.0397\n",
      "Epoch 25/300\n",
      " - 0s - loss: 0.0038 - mse: 0.0038 - mae: 0.0398\n",
      "Epoch 26/300\n",
      " - 0s - loss: 0.0036 - mse: 0.0036 - mae: 0.0393\n",
      "Epoch 27/300\n",
      " - 0s - loss: 0.0036 - mse: 0.0036 - mae: 0.0389\n",
      "Epoch 28/300\n",
      " - 0s - loss: 0.0035 - mse: 0.0035 - mae: 0.0385\n",
      "Epoch 29/300\n",
      " - 0s - loss: 0.0035 - mse: 0.0035 - mae: 0.0387\n",
      "Epoch 30/300\n",
      " - 0s - loss: 0.0035 - mse: 0.0035 - mae: 0.0382\n",
      "Epoch 31/300\n",
      " - 0s - loss: 0.0035 - mse: 0.0035 - mae: 0.0381\n",
      "Epoch 32/300\n",
      " - 0s - loss: 0.0035 - mse: 0.0035 - mae: 0.0383\n",
      "Epoch 33/300\n",
      " - 0s - loss: 0.0034 - mse: 0.0034 - mae: 0.0382\n",
      "Epoch 34/300\n",
      " - 0s - loss: 0.0034 - mse: 0.0034 - mae: 0.0382\n",
      "Epoch 35/300\n",
      " - 0s - loss: 0.0034 - mse: 0.0034 - mae: 0.0381\n",
      "Epoch 36/300\n",
      " - 0s - loss: 0.0034 - mse: 0.0034 - mae: 0.0378\n",
      "Epoch 37/300\n",
      " - 0s - loss: 0.0034 - mse: 0.0034 - mae: 0.0378\n",
      "Epoch 38/300\n",
      " - 0s - loss: 0.0034 - mse: 0.0034 - mae: 0.0376\n",
      "Epoch 39/300\n",
      " - 0s - loss: 0.0034 - mse: 0.0034 - mae: 0.0373\n",
      "Epoch 40/300\n",
      " - 0s - loss: 0.0033 - mse: 0.0033 - mae: 0.0377\n",
      "Epoch 41/300\n",
      " - 0s - loss: 0.0033 - mse: 0.0033 - mae: 0.0372\n",
      "Epoch 42/300\n",
      " - 0s - loss: 0.0033 - mse: 0.0033 - mae: 0.0375\n",
      "Epoch 43/300\n",
      " - 0s - loss: 0.0033 - mse: 0.0033 - mae: 0.0371\n",
      "Epoch 44/300\n",
      " - 0s - loss: 0.0033 - mse: 0.0033 - mae: 0.0372\n",
      "Epoch 45/300\n",
      " - 0s - loss: 0.0032 - mse: 0.0032 - mae: 0.0368\n",
      "Epoch 46/300\n",
      " - 0s - loss: 0.0032 - mse: 0.0032 - mae: 0.0370\n",
      "Epoch 47/300\n",
      " - 0s - loss: 0.0033 - mse: 0.0033 - mae: 0.0371\n",
      "Epoch 48/300\n",
      " - 0s - loss: 0.0032 - mse: 0.0032 - mae: 0.0368\n",
      "Epoch 49/300\n",
      " - 0s - loss: 0.0032 - mse: 0.0032 - mae: 0.0367\n",
      "Epoch 50/300\n",
      " - 0s - loss: 0.0033 - mse: 0.0033 - mae: 0.0370\n",
      "Epoch 51/300\n",
      " - 0s - loss: 0.0032 - mse: 0.0032 - mae: 0.0367\n",
      "Epoch 52/300\n",
      " - 0s - loss: 0.0032 - mse: 0.0032 - mae: 0.0369\n",
      "Epoch 53/300\n",
      " - 0s - loss: 0.0032 - mse: 0.0032 - mae: 0.0366\n",
      "Epoch 54/300\n",
      " - 0s - loss: 0.0032 - mse: 0.0032 - mae: 0.0363\n",
      "Epoch 55/300\n",
      " - 0s - loss: 0.0032 - mse: 0.0032 - mae: 0.0366\n",
      "Epoch 56/300\n",
      " - 0s - loss: 0.0032 - mse: 0.0032 - mae: 0.0365\n",
      "Epoch 57/300\n",
      " - 0s - loss: 0.0032 - mse: 0.0032 - mae: 0.0367\n",
      "Epoch 58/300\n",
      " - 0s - loss: 0.0031 - mse: 0.0031 - mae: 0.0362\n",
      "Epoch 59/300\n",
      " - 0s - loss: 0.0031 - mse: 0.0031 - mae: 0.0361\n",
      "Epoch 60/300\n",
      " - 0s - loss: 0.0032 - mse: 0.0032 - mae: 0.0364\n",
      "Epoch 61/300\n",
      " - 0s - loss: 0.0031 - mse: 0.0031 - mae: 0.0362\n",
      "Epoch 62/300\n",
      " - 0s - loss: 0.0031 - mse: 0.0031 - mae: 0.0359\n",
      "Epoch 63/300\n",
      " - 0s - loss: 0.0031 - mse: 0.0031 - mae: 0.0361\n",
      "Epoch 64/300\n",
      " - 0s - loss: 0.0031 - mse: 0.0031 - mae: 0.0361\n",
      "Epoch 65/300\n",
      " - 0s - loss: 0.0031 - mse: 0.0031 - mae: 0.0362\n",
      "Epoch 66/300\n",
      " - 0s - loss: 0.0031 - mse: 0.0031 - mae: 0.0360\n",
      "Epoch 67/300\n",
      " - 0s - loss: 0.0031 - mse: 0.0031 - mae: 0.0359\n",
      "Epoch 68/300\n",
      " - 0s - loss: 0.0031 - mse: 0.0031 - mae: 0.0361\n",
      "Epoch 69/300\n",
      " - 0s - loss: 0.0031 - mse: 0.0031 - mae: 0.0361\n",
      "Epoch 70/300\n",
      " - 0s - loss: 0.0031 - mse: 0.0031 - mae: 0.0358\n",
      "Epoch 71/300\n",
      " - 0s - loss: 0.0031 - mse: 0.0031 - mae: 0.0356\n",
      "Epoch 72/300\n",
      " - 0s - loss: 0.0030 - mse: 0.0030 - mae: 0.0355\n",
      "Epoch 73/300\n",
      " - 0s - loss: 0.0030 - mse: 0.0030 - mae: 0.0355\n",
      "Epoch 74/300\n",
      " - 0s - loss: 0.0030 - mse: 0.0030 - mae: 0.0357\n",
      "Epoch 75/300\n",
      " - 0s - loss: 0.0030 - mse: 0.0030 - mae: 0.0358\n",
      "Epoch 76/300\n",
      " - 0s - loss: 0.0031 - mse: 0.0031 - mae: 0.0359\n",
      "Epoch 77/300\n",
      " - 0s - loss: 0.0030 - mse: 0.0030 - mae: 0.0355\n",
      "Epoch 78/300\n",
      " - 0s - loss: 0.0030 - mse: 0.0030 - mae: 0.0354\n",
      "Epoch 79/300\n",
      " - 0s - loss: 0.0030 - mse: 0.0030 - mae: 0.0355\n",
      "Epoch 80/300\n",
      " - 1s - loss: 0.0030 - mse: 0.0030 - mae: 0.0357\n",
      "Epoch 81/300\n",
      " - 0s - loss: 0.0030 - mse: 0.0030 - mae: 0.0353\n",
      "Epoch 82/300\n",
      " - 0s - loss: 0.0031 - mse: 0.0031 - mae: 0.0356\n",
      "Epoch 83/300\n",
      " - 0s - loss: 0.0030 - mse: 0.0030 - mae: 0.0354\n",
      "Epoch 84/300\n",
      " - 0s - loss: 0.0030 - mse: 0.0030 - mae: 0.0355\n",
      "Epoch 85/300\n",
      " - 0s - loss: 0.0030 - mse: 0.0030 - mae: 0.0355\n",
      "Epoch 86/300\n",
      " - 0s - loss: 0.0030 - mse: 0.0030 - mae: 0.0354\n",
      "Epoch 87/300\n",
      " - 1s - loss: 0.0030 - mse: 0.0030 - mae: 0.0352\n",
      "Epoch 88/300\n",
      " - 0s - loss: 0.0030 - mse: 0.0030 - mae: 0.0349\n",
      "Epoch 89/300\n",
      " - 0s - loss: 0.0030 - mse: 0.0030 - mae: 0.0353\n",
      "Epoch 90/300\n",
      " - 0s - loss: 0.0029 - mse: 0.0029 - mae: 0.0351\n",
      "Epoch 91/300\n",
      " - 1s - loss: 0.0030 - mse: 0.0030 - mae: 0.0351\n",
      "Epoch 92/300\n",
      " - 0s - loss: 0.0029 - mse: 0.0029 - mae: 0.0350\n",
      "Epoch 93/300\n",
      " - 1s - loss: 0.0030 - mse: 0.0030 - mae: 0.0349\n",
      "Epoch 94/300\n",
      " - 0s - loss: 0.0030 - mse: 0.0030 - mae: 0.0352\n",
      "Epoch 95/300\n",
      " - 0s - loss: 0.0030 - mse: 0.0030 - mae: 0.0352\n",
      "Epoch 96/300\n",
      " - 0s - loss: 0.0029 - mse: 0.0029 - mae: 0.0351\n",
      "Epoch 97/300\n",
      " - 1s - loss: 0.0029 - mse: 0.0029 - mae: 0.0350\n",
      "Epoch 98/300\n",
      " - 0s - loss: 0.0030 - mse: 0.0030 - mae: 0.0354\n",
      "Epoch 99/300\n",
      " - 1s - loss: 0.0029 - mse: 0.0029 - mae: 0.0349\n",
      "Epoch 100/300\n",
      " - 0s - loss: 0.0029 - mse: 0.0029 - mae: 0.0349\n",
      "Epoch 101/300\n",
      " - 1s - loss: 0.0029 - mse: 0.0029 - mae: 0.0351\n",
      "Epoch 102/300\n",
      " - 0s - loss: 0.0029 - mse: 0.0029 - mae: 0.0350\n",
      "Epoch 103/300\n",
      " - 0s - loss: 0.0029 - mse: 0.0029 - mae: 0.0347\n",
      "Epoch 104/300\n",
      " - 0s - loss: 0.0029 - mse: 0.0029 - mae: 0.0350\n",
      "Epoch 105/300\n",
      " - 0s - loss: 0.0029 - mse: 0.0029 - mae: 0.0349\n",
      "Epoch 106/300\n",
      " - 0s - loss: 0.0029 - mse: 0.0029 - mae: 0.0347\n",
      "Epoch 107/300\n",
      " - 0s - loss: 0.0029 - mse: 0.0029 - mae: 0.0350\n",
      "Epoch 108/300\n",
      " - 0s - loss: 0.0029 - mse: 0.0029 - mae: 0.0347\n",
      "Epoch 109/300\n",
      " - 0s - loss: 0.0028 - mse: 0.0028 - mae: 0.0346\n",
      "Epoch 110/300\n",
      " - 0s - loss: 0.0029 - mse: 0.0029 - mae: 0.0347\n",
      "Epoch 111/300\n",
      " - 0s - loss: 0.0029 - mse: 0.0029 - mae: 0.0349\n",
      "Epoch 112/300\n",
      " - 0s - loss: 0.0029 - mse: 0.0029 - mae: 0.0344\n",
      "Epoch 113/300\n",
      " - 0s - loss: 0.0029 - mse: 0.0029 - mae: 0.0349\n",
      "Epoch 114/300\n",
      " - 0s - loss: 0.0029 - mse: 0.0029 - mae: 0.0346\n",
      "Epoch 115/300\n",
      " - 0s - loss: 0.0029 - mse: 0.0029 - mae: 0.0346\n",
      "Epoch 116/300\n",
      " - 0s - loss: 0.0029 - mse: 0.0029 - mae: 0.0346\n",
      "Epoch 117/300\n",
      " - 0s - loss: 0.0029 - mse: 0.0029 - mae: 0.0345\n",
      "Epoch 118/300\n",
      " - 0s - loss: 0.0029 - mse: 0.0029 - mae: 0.0347\n",
      "Epoch 119/300\n",
      " - 0s - loss: 0.0029 - mse: 0.0029 - mae: 0.0345\n",
      "Epoch 120/300\n",
      " - 0s - loss: 0.0029 - mse: 0.0029 - mae: 0.0346\n",
      "Epoch 121/300\n",
      " - 0s - loss: 0.0029 - mse: 0.0029 - mae: 0.0346\n",
      "Epoch 122/300\n",
      " - 0s - loss: 0.0029 - mse: 0.0029 - mae: 0.0345\n",
      "Epoch 123/300\n",
      " - 0s - loss: 0.0029 - mse: 0.0029 - mae: 0.0346\n",
      "Epoch 124/300\n",
      " - 0s - loss: 0.0028 - mse: 0.0028 - mae: 0.0343\n",
      "Epoch 125/300\n",
      " - 0s - loss: 0.0029 - mse: 0.0029 - mae: 0.0346\n",
      "Epoch 126/300\n",
      " - 0s - loss: 0.0029 - mse: 0.0029 - mae: 0.0348\n",
      "Epoch 127/300\n",
      " - 0s - loss: 0.0028 - mse: 0.0028 - mae: 0.0342\n",
      "Epoch 128/300\n",
      " - 0s - loss: 0.0028 - mse: 0.0028 - mae: 0.0344\n",
      "Epoch 129/300\n",
      " - 0s - loss: 0.0028 - mse: 0.0028 - mae: 0.0345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130/300\n",
      " - 0s - loss: 0.0028 - mse: 0.0028 - mae: 0.0345\n",
      "Epoch 131/300\n",
      " - 0s - loss: 0.0029 - mse: 0.0029 - mae: 0.0345\n",
      "Epoch 132/300\n",
      " - 0s - loss: 0.0028 - mse: 0.0028 - mae: 0.0343\n",
      "Epoch 133/300\n",
      " - 0s - loss: 0.0028 - mse: 0.0028 - mae: 0.0345\n",
      "Epoch 134/300\n",
      " - 0s - loss: 0.0028 - mse: 0.0028 - mae: 0.0344\n",
      "Epoch 135/300\n",
      " - 0s - loss: 0.0028 - mse: 0.0028 - mae: 0.0344\n",
      "Epoch 136/300\n",
      " - 0s - loss: 0.0028 - mse: 0.0028 - mae: 0.0341\n",
      "Epoch 137/300\n",
      " - 0s - loss: 0.0028 - mse: 0.0028 - mae: 0.0347\n",
      "Epoch 138/300\n",
      " - 0s - loss: 0.0028 - mse: 0.0028 - mae: 0.0341\n",
      "Epoch 139/300\n",
      " - 0s - loss: 0.0028 - mse: 0.0028 - mae: 0.0341\n",
      "Epoch 140/300\n",
      " - 0s - loss: 0.0028 - mse: 0.0028 - mae: 0.0341\n",
      "Epoch 141/300\n",
      " - 0s - loss: 0.0028 - mse: 0.0028 - mae: 0.0342\n",
      "Epoch 142/300\n",
      " - 0s - loss: 0.0028 - mse: 0.0028 - mae: 0.0342\n",
      "Epoch 143/300\n",
      " - 0s - loss: 0.0028 - mse: 0.0028 - mae: 0.0344\n",
      "Epoch 144/300\n",
      " - 0s - loss: 0.0028 - mse: 0.0028 - mae: 0.0341\n",
      "Epoch 145/300\n",
      " - 0s - loss: 0.0028 - mse: 0.0028 - mae: 0.0342\n",
      "Epoch 146/300\n",
      " - 0s - loss: 0.0028 - mse: 0.0028 - mae: 0.0341\n",
      "Epoch 147/300\n",
      " - 0s - loss: 0.0028 - mse: 0.0028 - mae: 0.0341\n",
      "Epoch 148/300\n",
      " - 0s - loss: 0.0028 - mse: 0.0028 - mae: 0.0342\n",
      "Epoch 149/300\n",
      " - 0s - loss: 0.0028 - mse: 0.0028 - mae: 0.0345\n",
      "Epoch 150/300\n",
      " - 0s - loss: 0.0028 - mse: 0.0028 - mae: 0.0341\n",
      "Epoch 151/300\n",
      " - 1s - loss: 0.0028 - mse: 0.0028 - mae: 0.0342\n",
      "Epoch 152/300\n",
      " - 0s - loss: 0.0028 - mse: 0.0028 - mae: 0.0342\n",
      "Epoch 153/300\n",
      " - 1s - loss: 0.0028 - mse: 0.0028 - mae: 0.0341\n",
      "Epoch 154/300\n",
      " - 1s - loss: 0.0028 - mse: 0.0028 - mae: 0.0341\n",
      "Epoch 155/300\n",
      " - 0s - loss: 0.0028 - mse: 0.0028 - mae: 0.0338\n",
      "Epoch 156/300\n",
      " - 0s - loss: 0.0028 - mse: 0.0028 - mae: 0.0342\n",
      "Epoch 157/300\n",
      " - 0s - loss: 0.0028 - mse: 0.0028 - mae: 0.0342\n",
      "Epoch 158/300\n",
      " - 1s - loss: 0.0028 - mse: 0.0028 - mae: 0.0340\n",
      "Epoch 159/300\n",
      " - 0s - loss: 0.0028 - mse: 0.0028 - mae: 0.0341\n",
      "Epoch 160/300\n",
      " - 0s - loss: 0.0028 - mse: 0.0028 - mae: 0.0342\n",
      "Epoch 161/300\n",
      " - 0s - loss: 0.0028 - mse: 0.0028 - mae: 0.0339\n",
      "Epoch 162/300\n",
      " - 0s - loss: 0.0028 - mse: 0.0028 - mae: 0.0340\n",
      "Epoch 163/300\n",
      " - 0s - loss: 0.0028 - mse: 0.0028 - mae: 0.0339\n",
      "Epoch 164/300\n",
      " - 0s - loss: 0.0027 - mse: 0.0027 - mae: 0.0337\n",
      "Epoch 165/300\n",
      " - 0s - loss: 0.0027 - mse: 0.0027 - mae: 0.0339\n",
      "Epoch 166/300\n",
      " - 0s - loss: 0.0028 - mse: 0.0028 - mae: 0.0338\n",
      "Epoch 167/300\n",
      " - 0s - loss: 0.0028 - mse: 0.0028 - mae: 0.0339\n",
      "Epoch 168/300\n",
      " - 0s - loss: 0.0028 - mse: 0.0028 - mae: 0.0340\n",
      "Epoch 169/300\n",
      " - 1s - loss: 0.0028 - mse: 0.0028 - mae: 0.0339\n",
      "Epoch 170/300\n",
      " - 0s - loss: 0.0027 - mse: 0.0027 - mae: 0.0337\n",
      "Epoch 171/300\n",
      " - 0s - loss: 0.0027 - mse: 0.0027 - mae: 0.0339\n",
      "Epoch 172/300\n",
      " - 0s - loss: 0.0027 - mse: 0.0027 - mae: 0.0335\n",
      "Epoch 173/300\n",
      " - 0s - loss: 0.0027 - mse: 0.0027 - mae: 0.0337\n",
      "Epoch 174/300\n",
      " - 0s - loss: 0.0028 - mse: 0.0028 - mae: 0.0337\n",
      "Epoch 175/300\n",
      " - 1s - loss: 0.0028 - mse: 0.0028 - mae: 0.0338\n",
      "Epoch 176/300\n",
      " - 0s - loss: 0.0027 - mse: 0.0027 - mae: 0.0338\n",
      "Epoch 177/300\n",
      " - 0s - loss: 0.0027 - mse: 0.0027 - mae: 0.0338\n",
      "Epoch 178/300\n",
      " - 0s - loss: 0.0027 - mse: 0.0027 - mae: 0.0337\n",
      "Epoch 179/300\n",
      " - 0s - loss: 0.0027 - mse: 0.0027 - mae: 0.0337\n",
      "Epoch 180/300\n",
      " - 0s - loss: 0.0027 - mse: 0.0027 - mae: 0.0339\n",
      "Epoch 181/300\n",
      " - 0s - loss: 0.0027 - mse: 0.0027 - mae: 0.0337\n",
      "Epoch 182/300\n",
      " - 0s - loss: 0.0028 - mse: 0.0028 - mae: 0.0337\n",
      "Epoch 183/300\n",
      " - 0s - loss: 0.0028 - mse: 0.0028 - mae: 0.0341\n",
      "Epoch 184/300\n",
      " - 0s - loss: 0.0027 - mse: 0.0027 - mae: 0.0337\n",
      "Epoch 185/300\n",
      " - 0s - loss: 0.0028 - mse: 0.0028 - mae: 0.0338\n",
      "Epoch 186/300\n",
      " - 0s - loss: 0.0027 - mse: 0.0027 - mae: 0.0337\n",
      "Epoch 187/300\n",
      " - 0s - loss: 0.0027 - mse: 0.0027 - mae: 0.0335\n",
      "Epoch 188/300\n",
      " - 1s - loss: 0.0027 - mse: 0.0027 - mae: 0.0337\n",
      "Epoch 189/300\n",
      " - 0s - loss: 0.0027 - mse: 0.0027 - mae: 0.0335\n",
      "Epoch 190/300\n",
      " - 0s - loss: 0.0027 - mse: 0.0027 - mae: 0.0336\n",
      "Epoch 191/300\n",
      " - 0s - loss: 0.0027 - mse: 0.0027 - mae: 0.0338\n",
      "Epoch 192/300\n",
      " - 0s - loss: 0.0027 - mse: 0.0027 - mae: 0.0334\n",
      "Epoch 193/300\n",
      " - 0s - loss: 0.0027 - mse: 0.0027 - mae: 0.0335\n",
      "Epoch 194/300\n",
      " - 0s - loss: 0.0027 - mse: 0.0027 - mae: 0.0337\n",
      "Epoch 195/300\n",
      " - 1s - loss: 0.0027 - mse: 0.0027 - mae: 0.0335\n",
      "Epoch 196/300\n",
      " - 0s - loss: 0.0027 - mse: 0.0027 - mae: 0.0335\n",
      "Epoch 197/300\n",
      " - 0s - loss: 0.0027 - mse: 0.0027 - mae: 0.0336\n",
      "Epoch 198/300\n",
      " - 0s - loss: 0.0028 - mse: 0.0028 - mae: 0.0335\n",
      "Epoch 199/300\n",
      " - 0s - loss: 0.0027 - mse: 0.0027 - mae: 0.0335\n",
      "Epoch 200/300\n",
      " - 0s - loss: 0.0027 - mse: 0.0027 - mae: 0.0335\n",
      "Epoch 201/300\n",
      " - 0s - loss: 0.0027 - mse: 0.0027 - mae: 0.0335\n",
      "Epoch 202/300\n",
      " - 0s - loss: 0.0027 - mse: 0.0027 - mae: 0.0336\n",
      "Epoch 203/300\n",
      " - 0s - loss: 0.0027 - mse: 0.0027 - mae: 0.0333\n",
      "Epoch 204/300\n",
      " - 0s - loss: 0.0027 - mse: 0.0027 - mae: 0.0335\n",
      "Epoch 205/300\n",
      " - 0s - loss: 0.0027 - mse: 0.0027 - mae: 0.0336\n",
      "Epoch 206/300\n",
      " - 0s - loss: 0.0027 - mse: 0.0027 - mae: 0.0334\n",
      "Epoch 207/300\n",
      " - 0s - loss: 0.0026 - mse: 0.0026 - mae: 0.0333\n",
      "Epoch 208/300\n",
      " - 1s - loss: 0.0027 - mse: 0.0027 - mae: 0.0333\n",
      "Epoch 209/300\n",
      " - 1s - loss: 0.0027 - mse: 0.0027 - mae: 0.0338\n",
      "Epoch 210/300\n",
      " - 0s - loss: 0.0027 - mse: 0.0027 - mae: 0.0335\n",
      "Epoch 211/300\n",
      " - 0s - loss: 0.0027 - mse: 0.0027 - mae: 0.0334\n",
      "Epoch 212/300\n",
      " - 0s - loss: 0.0027 - mse: 0.0027 - mae: 0.0333\n",
      "Epoch 213/300\n",
      " - 0s - loss: 0.0027 - mse: 0.0027 - mae: 0.0334\n",
      "Epoch 214/300\n",
      " - 0s - loss: 0.0027 - mse: 0.0027 - mae: 0.0334\n",
      "Epoch 215/300\n",
      " - 0s - loss: 0.0027 - mse: 0.0027 - mae: 0.0337\n",
      "Epoch 216/300\n",
      " - 0s - loss: 0.0026 - mse: 0.0026 - mae: 0.0332\n",
      "Epoch 217/300\n",
      " - 1s - loss: 0.0027 - mse: 0.0027 - mae: 0.0334\n",
      "Epoch 218/300\n",
      " - 0s - loss: 0.0026 - mse: 0.0026 - mae: 0.0333\n",
      "Epoch 219/300\n",
      " - 0s - loss: 0.0026 - mse: 0.0026 - mae: 0.0332\n",
      "Epoch 220/300\n",
      " - 0s - loss: 0.0026 - mse: 0.0026 - mae: 0.0332\n",
      "Epoch 221/300\n",
      " - 0s - loss: 0.0026 - mse: 0.0026 - mae: 0.0333\n",
      "Epoch 222/300\n",
      " - 0s - loss: 0.0026 - mse: 0.0026 - mae: 0.0332\n",
      "Epoch 223/300\n",
      " - 0s - loss: 0.0026 - mse: 0.0026 - mae: 0.0332\n",
      "Epoch 224/300\n",
      " - 0s - loss: 0.0027 - mse: 0.0027 - mae: 0.0333\n",
      "Epoch 225/300\n",
      " - 0s - loss: 0.0026 - mse: 0.0026 - mae: 0.0332\n",
      "Epoch 226/300\n",
      " - 0s - loss: 0.0027 - mse: 0.0027 - mae: 0.0333\n",
      "Epoch 227/300\n",
      " - 0s - loss: 0.0026 - mse: 0.0026 - mae: 0.0332\n",
      "Epoch 228/300\n",
      " - 0s - loss: 0.0027 - mse: 0.0027 - mae: 0.0334\n",
      "Epoch 229/300\n",
      " - 0s - loss: 0.0026 - mse: 0.0026 - mae: 0.0331\n",
      "Epoch 230/300\n",
      " - 0s - loss: 0.0026 - mse: 0.0026 - mae: 0.0334\n",
      "Epoch 231/300\n",
      " - 0s - loss: 0.0026 - mse: 0.0026 - mae: 0.0332\n",
      "Epoch 232/300\n",
      " - 0s - loss: 0.0026 - mse: 0.0026 - mae: 0.0331\n",
      "Epoch 233/300\n",
      " - 1s - loss: 0.0027 - mse: 0.0027 - mae: 0.0335\n",
      "Epoch 234/300\n",
      " - 0s - loss: 0.0027 - mse: 0.0027 - mae: 0.0334\n",
      "Epoch 235/300\n",
      " - 0s - loss: 0.0027 - mse: 0.0027 - mae: 0.0333\n",
      "Epoch 236/300\n",
      " - 1s - loss: 0.0027 - mse: 0.0027 - mae: 0.0333\n",
      "Epoch 237/300\n",
      " - 1s - loss: 0.0026 - mse: 0.0026 - mae: 0.0331\n",
      "Epoch 238/300\n",
      " - 0s - loss: 0.0026 - mse: 0.0026 - mae: 0.0330\n",
      "Epoch 239/300\n",
      " - 1s - loss: 0.0026 - mse: 0.0026 - mae: 0.0332\n",
      "Epoch 240/300\n",
      " - 0s - loss: 0.0027 - mse: 0.0027 - mae: 0.0331\n",
      "Epoch 241/300\n",
      " - 0s - loss: 0.0026 - mse: 0.0026 - mae: 0.0332\n",
      "Epoch 242/300\n",
      " - 0s - loss: 0.0026 - mse: 0.0026 - mae: 0.0330\n",
      "Epoch 243/300\n",
      " - 0s - loss: 0.0026 - mse: 0.0026 - mae: 0.0331\n",
      "Epoch 244/300\n",
      " - 0s - loss: 0.0026 - mse: 0.0026 - mae: 0.0329\n",
      "Epoch 245/300\n",
      " - 0s - loss: 0.0026 - mse: 0.0026 - mae: 0.0331\n",
      "Epoch 246/300\n",
      " - 0s - loss: 0.0026 - mse: 0.0026 - mae: 0.0330\n",
      "Epoch 247/300\n",
      " - 0s - loss: 0.0027 - mse: 0.0027 - mae: 0.0333\n",
      "Epoch 248/300\n",
      " - 0s - loss: 0.0026 - mse: 0.0026 - mae: 0.0331\n",
      "Epoch 249/300\n",
      " - 0s - loss: 0.0026 - mse: 0.0026 - mae: 0.0330\n",
      "Epoch 250/300\n",
      " - 0s - loss: 0.0026 - mse: 0.0026 - mae: 0.0332\n",
      "Epoch 251/300\n",
      " - 0s - loss: 0.0026 - mse: 0.0026 - mae: 0.0330\n",
      "Epoch 252/300\n",
      " - 0s - loss: 0.0026 - mse: 0.0026 - mae: 0.0330\n",
      "Epoch 253/300\n",
      " - 0s - loss: 0.0026 - mse: 0.0026 - mae: 0.0330\n",
      "Epoch 254/300\n",
      " - 0s - loss: 0.0026 - mse: 0.0026 - mae: 0.0330\n",
      "Epoch 255/300\n",
      " - 0s - loss: 0.0026 - mse: 0.0026 - mae: 0.0329\n",
      "Epoch 256/300\n",
      " - 0s - loss: 0.0026 - mse: 0.0026 - mae: 0.0330\n",
      "Epoch 257/300\n",
      " - 0s - loss: 0.0026 - mse: 0.0026 - mae: 0.0331\n",
      "Epoch 258/300\n",
      " - 0s - loss: 0.0025 - mse: 0.0025 - mae: 0.0328\n",
      "Epoch 259/300\n",
      " - 0s - loss: 0.0026 - mse: 0.0026 - mae: 0.0332\n",
      "Epoch 260/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.0026 - mse: 0.0026 - mae: 0.0330\n",
      "Epoch 261/300\n",
      " - 0s - loss: 0.0026 - mse: 0.0026 - mae: 0.0330\n",
      "Epoch 262/300\n",
      " - 0s - loss: 0.0026 - mse: 0.0026 - mae: 0.0329\n",
      "Epoch 263/300\n",
      " - 0s - loss: 0.0026 - mse: 0.0026 - mae: 0.0330\n",
      "Epoch 264/300\n",
      " - 1s - loss: 0.0026 - mse: 0.0026 - mae: 0.0331\n",
      "Epoch 265/300\n",
      " - 1s - loss: 0.0026 - mse: 0.0026 - mae: 0.0330\n",
      "Epoch 266/300\n",
      " - 1s - loss: 0.0026 - mse: 0.0026 - mae: 0.0330\n",
      "Epoch 267/300\n",
      " - 0s - loss: 0.0026 - mse: 0.0026 - mae: 0.0330\n",
      "Epoch 268/300\n",
      " - 1s - loss: 0.0026 - mse: 0.0026 - mae: 0.0328\n",
      "Epoch 269/300\n",
      " - 1s - loss: 0.0026 - mse: 0.0026 - mae: 0.0327\n",
      "Epoch 270/300\n",
      " - 0s - loss: 0.0026 - mse: 0.0026 - mae: 0.0328\n",
      "Epoch 271/300\n",
      " - 1s - loss: 0.0026 - mse: 0.0026 - mae: 0.0327\n",
      "Epoch 272/300\n",
      " - 1s - loss: 0.0026 - mse: 0.0026 - mae: 0.0329\n",
      "Epoch 273/300\n",
      " - 1s - loss: 0.0026 - mse: 0.0026 - mae: 0.0327\n",
      "Epoch 274/300\n",
      " - 0s - loss: 0.0026 - mse: 0.0026 - mae: 0.0328\n",
      "Epoch 275/300\n",
      " - 1s - loss: 0.0026 - mse: 0.0026 - mae: 0.0327\n",
      "Epoch 276/300\n",
      " - 1s - loss: 0.0026 - mse: 0.0026 - mae: 0.0327\n",
      "Epoch 277/300\n",
      " - 1s - loss: 0.0026 - mse: 0.0026 - mae: 0.0330\n",
      "Epoch 278/300\n",
      " - 1s - loss: 0.0026 - mse: 0.0026 - mae: 0.0328\n",
      "Epoch 279/300\n",
      " - 1s - loss: 0.0026 - mse: 0.0026 - mae: 0.0329\n",
      "Epoch 280/300\n",
      " - 1s - loss: 0.0025 - mse: 0.0025 - mae: 0.0325\n",
      "Epoch 281/300\n",
      " - 1s - loss: 0.0026 - mse: 0.0026 - mae: 0.0329\n",
      "Epoch 282/300\n",
      " - 1s - loss: 0.0026 - mse: 0.0026 - mae: 0.0332\n",
      "Epoch 283/300\n",
      " - 1s - loss: 0.0026 - mse: 0.0026 - mae: 0.0329\n",
      "Epoch 284/300\n",
      " - 0s - loss: 0.0026 - mse: 0.0026 - mae: 0.0329\n",
      "Epoch 285/300\n",
      " - 0s - loss: 0.0026 - mse: 0.0026 - mae: 0.0330\n",
      "Epoch 286/300\n",
      " - 0s - loss: 0.0026 - mse: 0.0026 - mae: 0.0332\n",
      "Epoch 287/300\n",
      " - 0s - loss: 0.0026 - mse: 0.0026 - mae: 0.0328\n",
      "Epoch 288/300\n",
      " - 1s - loss: 0.0025 - mse: 0.0025 - mae: 0.0327\n",
      "Epoch 289/300\n",
      " - 0s - loss: 0.0026 - mse: 0.0026 - mae: 0.0329\n",
      "Epoch 290/300\n",
      " - 0s - loss: 0.0026 - mse: 0.0026 - mae: 0.0327\n",
      "Epoch 291/300\n",
      " - 0s - loss: 0.0026 - mse: 0.0026 - mae: 0.0329\n",
      "Epoch 292/300\n",
      " - 0s - loss: 0.0026 - mse: 0.0026 - mae: 0.0329\n",
      "Epoch 293/300\n",
      " - 0s - loss: 0.0025 - mse: 0.0025 - mae: 0.0324\n",
      "Epoch 294/300\n",
      " - 0s - loss: 0.0026 - mse: 0.0026 - mae: 0.0327\n",
      "Epoch 295/300\n",
      " - 0s - loss: 0.0026 - mse: 0.0026 - mae: 0.0326\n",
      "Epoch 296/300\n",
      " - 0s - loss: 0.0026 - mse: 0.0026 - mae: 0.0329\n",
      "Epoch 297/300\n",
      " - 0s - loss: 0.0025 - mse: 0.0025 - mae: 0.0326\n",
      "Epoch 298/300\n",
      " - 0s - loss: 0.0025 - mse: 0.0025 - mae: 0.0328\n",
      "Epoch 299/300\n",
      " - 0s - loss: 0.0025 - mse: 0.0025 - mae: 0.0326\n",
      "Epoch 300/300\n",
      " - 0s - loss: 0.0025 - mse: 0.0025 - mae: 0.0327\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1431d97c508>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model = KerasRegressor(build_fn=best_model,epochs=300, \n",
    "    batch_size=parameters['batch_size'], verbose=2)    \n",
    "my_model.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find highest contributing features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-d2cf412a5f7c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0meli5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mperm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPermutationImportance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmy_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mweight_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meli5\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexplain_weights_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mperm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mlargest_10\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweight_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlargest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'weight'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\venv\\lib\\site-packages\\eli5\\sklearn\\permutation_importance.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    200\u001b[0m             \u001b[0msi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cv_scores_importances\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgroups\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 202\u001b[1;33m             \u001b[0msi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_non_cv_scores_importances\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    203\u001b[0m         \u001b[0mscores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscores_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\venv\\lib\\site-packages\\eli5\\sklearn\\permutation_importance.py\u001b[0m in \u001b[0;36m_non_cv_scores_importances\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    224\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_non_cv_scores_importances\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[0mscore_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscorer_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrapped_estimator_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m         \u001b[0mbase_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimportances\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_score_importances\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbase_score\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimportances\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimportances\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\venv\\lib\\site-packages\\eli5\\sklearn\\permutation_importance.py\u001b[0m in \u001b[0;36m_get_score_importances\u001b[1;34m(self, score_func, X, y)\u001b[0m\n\u001b[0;32m    229\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_score_importances\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m         return get_score_importances(score_func, X, y, n_iter=self.n_iter,\n\u001b[1;32m--> 231\u001b[1;33m                                      random_state=self.rng_)\n\u001b[0m\u001b[0;32m    232\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\venv\\lib\\site-packages\\eli5\\permutation_importance.py\u001b[0m in \u001b[0;36mget_score_importances\u001b[1;34m(score_func, X, y, n_iter, columns_to_shuffle, random_state)\u001b[0m\n\u001b[0;32m     89\u001b[0m         scores_shuffled = _get_scores_shufled(\n\u001b[0;32m     90\u001b[0m             \u001b[0mscore_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns_to_shuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns_to_shuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrng\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         )\n\u001b[0;32m     93\u001b[0m         \u001b[0mscores_decreases\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mscores_shuffled\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mbase_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\venv\\lib\\site-packages\\eli5\\permutation_importance.py\u001b[0m in \u001b[0;36m_get_scores_shufled\u001b[1;34m(score_func, X, y, columns_to_shuffle, random_state)\u001b[0m\n\u001b[0;32m     98\u001b[0m                         random_state=None):\n\u001b[0;32m     99\u001b[0m     \u001b[0mXs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter_shuffled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns_to_shuffle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mscore_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_shuffled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX_shuffled\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mXs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\venv\\lib\\site-packages\\eli5\\permutation_importance.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     98\u001b[0m                         random_state=None):\n\u001b[0;32m     99\u001b[0m     \u001b[0mXs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter_shuffled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns_to_shuffle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mscore_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_shuffled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX_shuffled\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mXs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\venv\\lib\\site-packages\\eli5\\sklearn\\permutation_importance.py\u001b[0m in \u001b[0;36mpd_scorer\u001b[1;34m(model, X, y)\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mpd_scorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd_columns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mbase_scorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpd_scorer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_scorer.py\u001b[0m in \u001b[0;36m_passthrough_scorer\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_passthrough_scorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    370\u001b[0m     \u001b[1;34m\"\"\"Function that wraps estimator.score\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 371\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    372\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    342\u001b[0m         \"\"\"\n\u001b[0;32m    343\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter_sk_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 344\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    345\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    346\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1359\u001b[0m                                          \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1360\u001b[0m                                          \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1361\u001b[1;33m                                          callbacks=callbacks)\n\u001b[0m\u001b[0;32m   1362\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1363\u001b[0m     def predict(self, x,\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mtest_loop\u001b[1;34m(model, f, ins, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[0;32m    447\u001b[0m             \u001b[0mbatch_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'batch'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'size'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'begin'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    450\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3275\u001b[0m         \u001b[0mtensor_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtypes_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3276\u001b[0m         array_vals.append(np.asarray(value,\n\u001b[1;32m-> 3277\u001b[1;33m                                      dtype=tensor_type.as_numpy_dtype))\n\u001b[0m\u001b[0;32m   3278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3279\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m     \"\"\"\n\u001b[1;32m--> 538\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from eli5.sklearn import PermutationImportance\n",
    "import eli5\n",
    "\n",
    "perm = PermutationImportance(my_model, random_state=1).fit(train_x,train_y)\n",
    "weight_df = eli5.explain_weights_df(perm, feature_names = train_x.columns.tolist(), )\n",
    "largest_10 = weight_df.nlargest(10,['weight'])\n",
    "largest_10['feature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals= np.array(weight_df['weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "bar() missing 1 required positional argument: 'height'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-8fa1fd349279>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpyplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: bar() missing 1 required positional argument: 'height'"
     ]
    }
   ],
   "source": [
    "pyplot.bar(vals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([6., 1., 1., 1., 0., 0., 0., 0., 0., 1.]),\n",
       " array([0.0005107 , 0.00117317, 0.00183563, 0.0024981 , 0.00316057,\n",
       "        0.00382303, 0.0044855 , 0.00514797, 0.00581043, 0.0064729 ,\n",
       "        0.00713537]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.hist(np.array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['boligtype_Leilighet','boligtype_Enebolig','bruksareal','boligtype_Tomannsbolig','postnummer','boligtype_Rekkehus', \n",
    "        'neighborhood_environment_demographics_housingage_10-30','neighborhood_environment_demographics_housingprices_0-2000000','neighborhood_environment_demographics_housingage_30-50',\n",
    "        'eieform_Andel']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10-feature model training (Ferdigtrent, lastes inn lenger ned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "features = ['boligtype_Leilighet','boligtype_Enebolig','bruksareal','boligtype_Tomannsbolig','postnummer','boligtype_Rekkehus', \n",
    "'neighborhood_environment_demographics_housingage_10-30','neighborhood_environment_demographics_housingprices_0-2000000','neighborhood_environment_demographics_housingage_30-50',\n",
    "'eieform_Andel']\n",
    "train_x = train_x[features]\n",
    "validation_x = validation_x[features]\n",
    "test_x = test_x[features] \n",
    "\n",
    "parameters = {'activation_1':['relu', 'elu', 'sigmoid', 'tanh'],\n",
    " 'activation_2':['relu', 'elu', 'sigmoid', 'tanh'],\n",
    " 'activation_3':['relu', 'elu', 'sigmoid', 'tanh'],\n",
    " 'optimizer': ['Adam', \"RMSprop\", 'sgd', 'Nadam'],\n",
    " 'loss-functions': ['mse'],\n",
    " 'neurons_HL1': [5, 10, 20, 50, 100],\n",
    " 'neurons_HL2': [5, 10, 20, 50, 100],\n",
    " 'neurons_HL3': [5, 10, 20, 50, 100, None],\n",
    " 'dropout1': [0.1, 0.2, 0.3],\n",
    " 'dropout2': [0.0, 0.1, 0.2, 0.3],\n",
    " 'batch_size': [100, 250, 500],\n",
    " 'epochs': [3000]\n",
    "}\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def talolos(x_train, y_train, x_val, y_val, parameters):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(parameters['neurons_HL1'],\n",
    "                    input_shape=(train_x.shape[1],),\n",
    "                    activation=parameters['activation_1'], use_bias=True))\n",
    "\n",
    "    model.add(Dropout(parameters['dropout1']))\n",
    "    model.add(Dense(parameters['neurons_HL2'], activation=parameters['activation_2'], use_bias=True))\n",
    "    model.add(Dropout(parameters['dropout1']))\n",
    "\n",
    "    if parameters['neurons_HL3']:\n",
    "        model.add(Dense(parameters['neurons_HL3'], activation=parameters['activation_3'], use_bias=True))\n",
    "\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "    model.compile(optimizer=parameters['optimizer'], loss=parameters['loss-functions'], metrics=['mse', 'mae'])\n",
    "\n",
    "    history = model.fit(x_train, y_train,\n",
    "                        batch_size=parameters['batch_size'], epochs=parameters['epochs'],\n",
    "                        verbose=0, validation_data=[x_val, y_val],\n",
    "                        callbacks=[early_stopper(epochs=parameters['epochs'],\n",
    "                                                 mode='moderate', monitor='val_loss', patience=40)])\n",
    "\n",
    "    return history, model\n",
    "\n",
    "t = talos.Scan(x=np.array(train_x),\n",
    "               y=np.array(train_y),\n",
    "               x_val=np.array(validation_x),\n",
    "               y_val=np.array(validation_y),\n",
    "               model=talolos,\n",
    "               params=parameters,\n",
    "               experiment_name='talos_training',\n",
    "               round_limit=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_model_10 = t.best_model(metric='loss', asc=True)\n",
    "best_model_10.save(f'../talos_training/best_model_10.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load 10-best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "best_model_10 = load_model(f'../talos_training/best_model_10.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame()\n",
    "predictions['pred'] = my_model.predict(test_x)\n",
    "print(predictions['pred'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
